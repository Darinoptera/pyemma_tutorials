{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - common problems & bad data situations\n",
    "In this notebook, we will revise common problems that might come up when dealing with real-world data. Most problems arise from bad sampling combined with a poor discretization. For estimating a Markov model, it is required to have a connected data set, i.e. we must have observed each process we want to describe in both directions. PyEMMA checks if this requirement is fulfilled, however in certain situations this might be less obvious.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pyemma.datasets\n",
    "import numpy as np\n",
    "import mdshare\n",
    "import pyemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: preprocessed, two-dimensional data (toy model)\n",
    "### well-sampled double-well potential\n",
    "Let's again have a look at the double-well potential. Since we are only interested in the problematic situations here, we will simplify our data a bit and work with a 1D TICA projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = mdshare.fetch('hmm-doublewell-2d-100k.npz', working_directory='data')\n",
    "with np.load(file) as fh:\n",
    "    data = fh['trajectory']\n",
    "trjs = pyemma.coordinates.tica(data).get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1D_histogram_trajectories(trjs, cl=None, max_traj_length=200, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    for n, _traj in enumerate(trjs):\n",
    "        ax.hist(_traj, bins=30, alpha=.33, density=True, color='C{}'.format(n));\n",
    "    ylims = ax.get_ylim()\n",
    "    xlims = ax.get_xlim()\n",
    "    for n, _traj in enumerate(trjs):\n",
    "        ax.plot(_traj[:min(len(_traj), max_traj_length)], \n",
    "                np.linspace(*ylims, min(len(_traj), max_traj_length)), \n",
    "                alpha=.6, color='C{}'.format(n), label='traj {}'.format(n))\n",
    "        if cl is not None:\n",
    "            ax.plot(cl.clustercenters[cl.dtrajs[n][:min(len(_traj), max_traj_length)], 0], \n",
    "                    np.linspace(*ylims, min(len(_traj), max_traj_length)), \n",
    "                    '.-', alpha=.6, label='dtraj {}'.format(n), linewidth=.3)\n",
    "    ax.annotate('', xy=(.85 * xlims[1], .7 * ylims[1]), xytext=(.85 * xlims[1], .3 * ylims[1]),\n",
    "        arrowprops=dict(fc='C0', ec='None', alpha=.6, width=2))\n",
    "    ax.text(.86 * xlims[1], .5 * ylims[1], '$x(time)$', ha=\"left\", va=\"center\", rotation=90)\n",
    "    ax.set_xlabel('TICA coordinate')\n",
    "    ax.set_ylabel('histogram counts & trajecotory time')\n",
    "    ax.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "cl = pyemma.coordinates.cluster_regspace(trjs, dmin=.05)\n",
    "\n",
    "plot_1D_histogram_trajectories(trjs, cl=cl, ax=ax[0])\n",
    "\n",
    "lags = [i + 1 for i in range(10)]\n",
    "its = pyemma.msm.its(cl.dtrajs, lags=lags)\n",
    "pyemma.plots.plot_implied_timescales(its, marker='o', ax=ax[1], nits=4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a nice, reversibly connected trajectory. That means we have sampled transitions between the basins in both directions and are resolved by the discretization. As we see from the almost perfect overlay of discrete and continuous trajectory, nearly no discretization error is made. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  irreversibly connected double-well trajectories\n",
    "In MD simulations, we often face the problem that a process is sampled only in one direction. For example, consider protein-protein binding. The unbinding might take on the order of seconds to minutes and is thus difficult to sample. We will have a look what happens with the MSM in this case. \n",
    "\n",
    "Our example are two trajectories sampled from a double-well potential. They will be color coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = mdshare.fetch('doublewell_oneway.npy', working_directory='data')\n",
    "trjs = [trj for trj in np.load(file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1D_histogram_trajectories(trjs, max_traj_length=trjs[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the orange trajectory does not leave its potential well while the blue trajectory does a transition to the other well. Thus, even though we have one transition, we do not sample the way out of one of the potential wells, thus effectively sampling a sink state. Let's have a look at the MSM. Since in higher dimensions, we often face the problem of a poor discretization, we will simulate this situation by using too few cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl_fine = pyemma.coordinates.cluster_regspace(trjs, dmin=.1)\n",
    "cl_bad = pyemma.coordinates.cluster_regspace(trjs, dmin=.7)\n",
    "print(cl_fine.n_clusters, cl_bad.n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharey='col')\n",
    "\n",
    "for cl, ax in zip([cl_bad, cl_fine], axes):\n",
    "\n",
    "    plot_1D_histogram_trajectories(trjs, cl=cl, max_traj_length=trjs[0].shape[0], ax=ax[0])\n",
    "\n",
    "    its = pyemma.msm.its(cl.dtrajs, lags=[1, 10, 100, 200, 300, 500, 800, 1000])\n",
    "    pyemma.plots.plot_implied_timescales(its, marker='o', ax=ax[1], nits=4)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we see? \n",
    "\n",
    "1) We observe implied timescales that even look converged in the fine sampling case. \n",
    "\n",
    "2) With poor sampling, the process cannot be resolved any more i.e. the ITS does not convergence before the lag time exceeds the implied time scale. \n",
    "\n",
    "The obvious question is, what is the process that can be observed in the fine discretization case? PyEMMA checks for disconnectivity and thus should not find the process between the two wells. We follow this question by taking a look at the first eigenvector, which corresponds to that process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pyemma.msm.estimate_markov_model(cl_fine.dtrajs, 200)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(cl_fine.clustercenters[m.active_set, 0], m.eigenvectors_right()[:, 1], 'o:', label='first eigvec')\n",
    "tx = ax.twinx()\n",
    "tx.hist(np.concatenate(trjs), bins=30, alpha=.33)\n",
    "tx.set_yticklabels([]); tx.set_yticks([])\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a process which is entirely taking place in the left potential well. How come? PyEMMA estimates Markov models only on the largest connected set, as MSMs are only defined here. In this particular example, the largest connected set is the microstates in the left potential well. That means that we find a transition between the right and the left side of this well. This is not wrong, it might just be non-informative or irrelevant. \n",
    "\n",
    "The set of microstates which is used for the MSM estimation is stored in the MSM python object and can be retrieved via `.active_set`. In this example we clearly see that some states are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.active_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disconnected double-well trajectories with cross-overs\n",
    "This example covers the worst-case scenario. We have two trajectories that live in two separated wells and never transition to the other one. Due to a very bad clustering, we believe that the data is connected. This can happen if we cluster a large dataset in very high dimensions where it is especially difficult to debug. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = mdshare.fetch('doublewell_disconnected.npy', working_directory='data')\n",
    "trjs = [trj for trj in np.load(file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1D_histogram_trajectories(trjs, max_traj_length=trjs[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_fine = pyemma.coordinates.cluster_regspace(trjs, dmin=.1)\n",
    "cl_bad = pyemma.coordinates.cluster_regspace(trjs, dmin=.7)\n",
    "print(cl_fine.n_clusters, cl_bad.n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharey='col')\n",
    "\n",
    "for cl, ax in zip([cl_bad, cl_fine], axes):\n",
    "\n",
    "    plot_1D_histogram_trajectories(trjs, cl=cl, max_traj_length=trjs[0].shape[0], ax=ax[0])\n",
    "\n",
    "    its = pyemma.msm.its(cl.dtrajs, lags=[1, 10, 100, 200, 300, 500, 800, 1000])\n",
    "    pyemma.plots.plot_implied_timescales(its, marker='o', ax=ax[1], nits=4)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we see?\n",
    "\n",
    "1) With the fine discretization, we observe some timescales that are converged. These are most probably processes within one of the wells as we say previously.\n",
    "\n",
    "2) The poor discretization introduces a large error and describes short visits to the other basin.\n",
    "\n",
    "3) The timescales in the poor discretization are much higher but not converged. \n",
    "\n",
    "The reason for the high timescales of the poor discretization are in fact the artificial cross-over events created by the poor discretization. This process was not actually sampled and is an artifact of bad clustering. Let's look at it in more detail anyway and even compute metastable states with a PCCA+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pyemma.msm.estimate_markov_model(cl_bad.dtrajs, 200)\n",
    "m.pcca(2)\n",
    "index_order = np.argsort(cl_bad.clustercenters[:, 0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "ax[0].plot(cl_bad.clustercenters[index_order, 0], m.eigenvectors_right()[index_order, 1], 'o:', label='first eigvec')\n",
    "ax[0].set_title('first eigenvector')\n",
    "\n",
    "for n, metastable_distribution in enumerate(m.metastable_distributions):\n",
    "    ax[1].step(cl_bad.clustercenters[index_order, 0], metastable_distribution[index_order], ':', \n",
    "               label='metastable distr state {}'.format(n), where='mid')\n",
    "ax[1].set_title('metastable distributions')\n",
    "ax[2].step(cl_bad.clustercenters[index_order, 0], m.pi[index_order], 'k--', label='stationary_distribution', where='mid')\n",
    "ax[2].set_title('stat dist')\n",
    "\n",
    "for _ax in ax:\n",
    "    tx = _ax.twinx()\n",
    "    tx.hist(np.concatenate(trjs), bins=30, alpha=.33)\n",
    "    tx.set_yticklabels([]); tx.set_yticks([])\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the first eigenvector represents a process that does not exist, i.e. is an artifact. Nevertheless, the PCCA+ algorithm can separate metastable states in a way we would expect. It finds the two disconnected states. However, the stationary distribution yields arbitrary results. \n",
    "\n",
    "#### How to detect disconnectivity?\n",
    "Generally, hidden Markov models (HMMs) are much more reliable because they come with an additional layer of hidden states. Cross-over events are thus unlikely to be counted as \"real\" transitions. Thus, it is a good idea to estimate an HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "its = pyemma.msm.timescales_hmsm(cl_bad.dtrajs, 2, lags=[1, 10, 100, 200, 300, 500, 800, 1000])\n",
    "pyemma.plots.plot_implied_timescales(its, marker='o', ylog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, most of the requested timescales could not be computed because the underlying HMM is disconnected (a.k.a. there are multiple eigenvalues with magnitude one). What happens if we take our previously estimated MSM and coarse grain it into two states with the HMM method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: something wrong with pyEMMA behavior. #1312."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = m.coarse_grain(2)\n",
    "print('Implied timescale: ', hmm.timescales())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting an implied timescale which is infinity. This in a sense corresponds to the original, unconverged MSM time scale displayed above. The HMM captures the value that was underestimated by the MSM. Let's compare this to the fine state space discretization by estimating a new HMM.\n",
    "\n",
    "What does this mean? The HMM estimates that the state does not decay, i.e. the time it takes to fall back to the equilibrium distribution is infinity. This means that the disconnectivity has been detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pyemma.msm.estimate_markov_model(cl_fine.dtrajs, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_finediscretization = pyemma.msm.estimate_hidden_markov_model(cl_fine.dtrajs, 2, 200)\n",
    "print('Implied timescale: ', hmm.timescales())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that still that the implied time scale is infinity. That means that the effect of the bad discretization on the HMM estimation is not visible in this example. We find that the metastable distribution is similar to the one estimated by PCCA+ and separates the two potential wells independently of the quality of the discretization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "index_order = np.argsort(cl_bad.clustercenters[:, 0])\n",
    "for n, metastable_distribution in enumerate(hmm.metastable_distributions):\n",
    "    ax.step(cl_bad.clustercenters[index_order, 0], metastable_distribution[index_order], ':', \n",
    "               where='mid', color='C'+str(n), label='HMM state '+str(n))\n",
    "index_order = np.argsort(cl_fine.clustercenters[:, 0])\n",
    "for n, metastable_distribution in enumerate(hmm_finediscretization.metastable_distributions):\n",
    "    ax.step(cl_fine.clustercenters[index_order, 0], metastable_distribution[index_order], ':', \n",
    "               where='mid', color='C'+str(1-n))\n",
    "tx = ax.twinx()\n",
    "tx.hist(np.concatenate(trjs), bins=30, alpha=.33)\n",
    "tx.set_yticklabels([]); tx.set_yticks([])\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the metastable state number is arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: low-dimensional molecular dynamics data (alanine dipeptide)\n",
    "In this example, we will show how an ill-conducted TICA analysis can yield results that look metastable in the 2D histogram, but in fact are not describing the slow dynamics. Please note that this was deliberately broken with a nonsensical TICA-lagtime of almost trajectory length, which is 250 ns.\n",
    "\n",
    "We start off with adding all atom coordinates. That's a non-optimal choice because it artificially blows up the dimensionality, but might still a reasonable choice depending on the problem. A well-conducted TICA projection can extract the slow coordinates, as we will see at the end of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('alanine-dipeptide-nowater.pdb', working_directory='data')\n",
    "files = mdshare.fetch('alanine-dipeptide-*-250ns-nowater.dcd', working_directory='data')\n",
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "\n",
    "feat.add_all()\n",
    "data = pyemma.coordinates.load(files, features=feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TICA analysis is conducted with an extremely high lag time of almost 249.9 ns. We map down to two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(data, lag=data[0].shape[0]-100, dim=2)\n",
    "inp = tica.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemma.plots.plot_free_energy(*np.concatenate(inp).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the free energy plot, we recognize two defined basins that are nicely separated by the first TIC. We thus continue with a discretization of this space and estimate MSM implied timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = pyemma.coordinates.cluster_kmeans(inp, k=200, max_iter=30, stride=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = pyemma.msm.its(clustering.dtrajs, lags=[1, 5, 10, 20, 30, 50])\n",
    "pyemma.plots.plot_implied_timescales(its, marker='o', units='ps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we observe a converged timescale. In this example we already know that it is way lower than expected, but in the general case we are unaware of the real dynamics of the system. Thus, we estimate an MSM at lag time 20. Coarse graining and validation will be done with 2 metastable states since we found 2 basins in the free energy landscape and have one slow process in the ITS plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(clustering.dtrajs, 20)\n",
    "msm.pcca(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 10\n",
    "metastable_trajs_strided = [msm.metastable_assignments[dtrj[::stride]] for dtrj in clustering.dtrajs]\n",
    "tica_trajs_strided = [i[::stride] for i in inp]\n",
    "plt.scatter(*np.concatenate(tica_trajs_strided).T, s=1, c=np.concatenate(metastable_trajs_strided))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the PCCA+ algorithm is perfectly able to separate the two basins. Let's go on with a Chapman-Kolmogorow validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemma.plots.plot_cktest(msm.cktest(2), units='ps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, we have estimated a well-validated Markov model. The only question remaining is: What does it actually describe? For this, we usually extract representative structures as described in a previous notebook. \n",
    "\n",
    "#### What could be wrong about it?\n",
    "Let's have a look at the trajectories as assigned to PCCA coarse states. We have already computed them before but not looked at their time dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 6), sharey=True, sharex=True)\n",
    "ax_yticks_labels = []\n",
    "for n, pcca_traj in enumerate(metastable_trajs_strided):\n",
    "    ax.plot(range(len(pcca_traj)), msm.n_metastable * n + pcca_traj, color='k', linewidth=.3)\n",
    "    ax.scatter(range(len(pcca_traj)), msm.n_metastable * n + pcca_traj, c=pcca_traj, s=.1)\n",
    "    ax_yticks_labels.append(((msm.n_metastable * (2*n+1) - 1)/2, n+1))\n",
    "ax.set_yticks([l[0] for l in ax_yticks_labels])\n",
    "ax.set_yticklabels([str(l[1]) for l in ax_yticks_labels])\n",
    "ax.set_ylabel('Trajectory #')\n",
    "ax.set_xlabel('time ({} ps)'.format(stride));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we see?\n",
    "The above figure shows the metastable states visited by the trajectory over time. Each metastable state is color-coded, the trajectory is shown by the black line. This is clearly not a metastable trajectory as we would have expected. What did we do wrong? Let's have a look at the TICA trajectories, not only the histogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15, 8), sharex=True, sharey='row')\n",
    "\n",
    "for n, trj in enumerate(inp):\n",
    "    for dim, traj1d in enumerate(trj.T):\n",
    "        ax[dim][n].plot(traj1d[::stride], linewidth=.5)\n",
    "for _ax in ax[1]: _ax.set_xlabel('time ({} ps)'.format(stride))\n",
    "for dim, _ax in enumerate(ax[:, 0]): _ax.set_ylabel('TIC{}'.format(dim))\n",
    "for n, _ax in enumerate(ax[0]): _ax.set_title('Trajectory # {}'.format(n+1))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially noise, so it is not surprising that the metastable trajectories do not show significant metastability. The MSM nevertheless found a process in the above TICs, which however does not seem to describe any of the slow dynamics. Thus, the model is not wrong, it is just uninformative. \n",
    "\n",
    "As we see in this example, it can be instructive to keep the trajectories in mind and not to rely on the histograms alone. Histograms are no proof of metastability, they can only give us a hint towards defined states in a multi-dimensional state space which can be metastable.\n",
    "\n",
    "#### How to fix it?\n",
    "In this particular example, we already know the issue: The TICA lag time was deliberately chosen way too high. That's easy to fix.\n",
    "\n",
    "Let's now have a look at how the metastable trajectories should look like for a decent model such as the one estimated in the previous notebooks. We will take the same input data, do a TICA transform with a realistic lag time of 10 ps and coarse grain into 2 metastable states in order to compare with the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(data, lag=10, dim=2)\n",
    "inp = tica.get_output()\n",
    "clustering = pyemma.coordinates.cluster_kmeans(inp, k=200, max_iter=30, stride=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemma.plots.plot_free_energy(*np.concatenate(inp).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As wee see, TICA yields a very nice state separation. We will see that these states are in fact metastable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(clustering.dtrajs, lag=20)\n",
    "msm.pcca(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metastable_trajs_strided = [msm.metastable_assignments[dtrj[::stride]] for dtrj in clustering.dtrajs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 10\n",
    "tica_trajs_strided = [i[::stride] for i in inp]\n",
    "plt.scatter(*np.concatenate(tica_trajs_strided).T, s=1, c=np.concatenate(metastable_trajs_strided))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that PCCA+ separates the two basins of the free energy plot. Let's have a look at the trajectories as assigned by PCCA+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 6), sharey=True, sharex=True)\n",
    "ax_yticks_labels = []\n",
    "for n, pcca_traj in enumerate(metastable_trajs_strided):\n",
    "    ax.plot(range(len(pcca_traj)), msm.n_metastable * n + pcca_traj, color='k', linewidth=.3)\n",
    "    ax.scatter(range(len(pcca_traj)), msm.n_metastable * n + pcca_traj, c=pcca_traj, s=.1)\n",
    "    ax_yticks_labels.append(((msm.n_metastable * (2*n+1) - 1)/2, n+1))\n",
    "ax.set_yticks([l[0] for l in ax_yticks_labels])\n",
    "ax.set_yticklabels([str(l[1]) for l in ax_yticks_labels])\n",
    "ax.set_ylabel('Trajectory #')\n",
    "ax.set_xlabel('time ({} ps)'.format(stride));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These trajectories show the expected behavior of a metastable trajectory, i.e. it does not quickly jump back and forth between the states. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "In this notebook, we have learned about some problems that can arise when estimating MSMs with \"real world\" data at simple examples. In detail, we have seen\n",
    "\n",
    "- irreversibly connected dynamics and what it means for MSM estimation,\n",
    "- fully disconnected trajectories and how to identify them,\n",
    "- ill-conducted TICA analysis and what it yields.\n",
    "\n",
    "The most important message from this tutorial is that histograms are not a means of identifying metastability or connectedness. One should not forgot about the underlying trajectories which should play the role of the ground truth to be modeled. Histograms only help us to understand this ground truth but are not necessarily meaningful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
