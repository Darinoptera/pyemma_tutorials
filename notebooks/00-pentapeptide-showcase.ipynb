{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Showcase Pentapeptide: A PyEMMA walkthrough\n",
    "In this notebook, we introduce the most basic features of PyEMMA. Overall, the notebook serves as an example workflow for analyzing molecular dynamics trajectories. Here, we keep the details to absolutely minimal and refer to the more specialized notebooks fleshing out each topic covered here in more details, including exercises and some theory. \n",
    "\n",
    "Maintainers: \n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"left\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import mdshare\n",
    "import pyemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data input and featurization\n",
    "We start our short walkthrough tutorial by loading a topology file (in this case, a PDB) and the trajectory data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('pentapeptide-impl-solv.pdb', working_directory='data')\n",
    "files = mdshare.fetch('pentapeptide-*-500ns-impl-solv.dcd', working_directory='data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell has downloaded the data from our servers; in general, only strings of file paths need to be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdb)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As from the beginning it is unknown which feature describes the system best, we start with a broad systematic analysis. For the sake of simplicity, we are only interested in modeling the backbone kinetics. Thus, we only consider features describing the backbone.\n",
    "\n",
    "In PyEMMA, the `featurizer` is a central object that incorporates the system's topology. Features are easily computed by adding the target feature e.g. with `featurizer.add_backbone_torsions()`. We will load backbone torsion angles, backbone heavy atom distances and backbone heavy atom distances. \n",
    "\n",
    "Please note that the structures have been aligned before. Since in that case, we loose track of the periodic box, we have to switch off the `periodic` flag for the distance and torsion angle computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torsions_feat = pyemma.coordinates.featurizer(pdb)\n",
    "torsions_feat.add_backbone_torsions(cossin=True, periodic=False)\n",
    "torsions_data = pyemma.coordinates.load(files, features=torsions_feat)\n",
    "labels = ['backbone\\ntorsions']\n",
    "\n",
    "positions_feat = pyemma.coordinates.featurizer(pdb)\n",
    "positions_feat.add_selection(positions_feat.select_Backbone())\n",
    "positions_data = pyemma.coordinates.load(files, features=positions_feat)\n",
    "labels += ['backbone atom\\npositions']\n",
    "\n",
    "distances_feat = pyemma.coordinates.featurizer(pdb)\n",
    "distances_feat.add_distances(\n",
    "    distances_feat.pairs(distances_feat.select_Backbone(), excluded_neighbors=2), periodic=False)\n",
    "distances_data = pyemma.coordinates.load(files, features=distances_feat)\n",
    "labels += ['backbone atom\\ndistances']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "#TODO: explain vamp-2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3), sharey=True)\n",
    "for ax, lag in zip(axes.flat, [5, 10, 20]):\n",
    "    torsions_vamp = pyemma.coordinates.vamp(torsions_data, lag=lag, dim=dim)\n",
    "    scores = [torsions_vamp.score()]\n",
    "    positions_vamp = pyemma.coordinates.vamp(positions_data, lag=lag, dim=dim)\n",
    "    scores += [positions_vamp.score()]\n",
    "    distances_vamp = pyemma.coordinates.vamp(distances_data, lag=lag, dim=dim)\n",
    "    scores += [distances_vamp.score()]\n",
    "    ax.bar(labels, scores)\n",
    "    ax.set_title(r'lag time $\\tau$={:.1f}ns'.format(lag * 0.1))\n",
    "    if lag == 5:\n",
    "        vamp_bars_plot = dict(labels=labels, scores=scores, dim=dim, lag=lag) # save for later\n",
    "axes[0].set_ylabel('VAMP2 score')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 5, 10, 20, 50]\n",
    "dims = [i + 1 for i in range(10)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for lag in lags:\n",
    "    scores = [pyemma.coordinates.vamp(torsions_data, lag=lag, dim=dim).score()\n",
    "              for dim in dims]\n",
    "    ax.plot(dims, scores, label='lag={:.1f}ns'.format(lag * 0.1))\n",
    "ax.legend()\n",
    "ax.set_xlabel('number of dimensions')\n",
    "ax.set_ylabel('VAMP2 score')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Explain why we chose lag 5 and the backbone torsions.\n",
    "\n",
    "### Coordinate transform and discretization\n",
    "\n",
    "The goal of the next step is to find a function that maps the usually high-dimensional input space into some lower dimensional space that captures the important dynamics. The recommended way of doing so is time-lagged independent component analysis (TICA). We perform TICA (with kinetic map scaling) using the lag time obtained from the VAMP-2 score. \n",
    "\n",
    "Please note the general `PyEMMA` API that applies to all estimators. By calling the TICA estimator with the data (`tica = pyemma.coordinates.tica(torisions_data)`), the estimation is done and an estimator instance returned (`tica`). It contains all the information about the specific entity and maps the input data by calling `tica.get_output()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(torsions_data, lag=5)\n",
    "tica_output = tica.get_output()\n",
    "tica_concatenated = np.concatenate(tica_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the marginal and joint distributions of our TICA components by simple histograming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_feature_histograms(tica_concatenated, ax=axes[0], ylog=True)\n",
    "pyemma.plots.plot_density(*tica_concatenated.T[:2], ax=axes[1], logscale=True)\n",
    "axes[1].set_xlabel('IC 1')\n",
    "axes[1].set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the projection yields defined clusters of high densities, that are most likely to be identified as metastable basins. \n",
    "\n",
    "Letâ€™s have a look how one of the trajectories looks like in the space of the first $4$ TICA components. We can see that the TICA components nicely resolve the slow transitions as discrete jumps. Thus, metastability is well-described in this projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1, figsize=(12, 5), sharex=True)\n",
    "x = 0.1 * np.arange(tica_output[0].shape[0])\n",
    "for i, (ax, tic) in enumerate(zip(axes.flat, tica_output[0].T)):\n",
    "    ax.plot(x, tic)\n",
    "    ax.set_ylabel('IC {}'.format(i + 1))\n",
    "axes[-1].set_xlabel('time / ns')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TICA coordinates are now clustered into a number of discrete states using the $k$-means algorithm. The $k$-means algorithm requires as input the number of clusters. The trajectories are automatically assigned to the cluster centers by calling `cluster.dtrajs`. \n",
    "\n",
    "It is a priori unclear what the optimal number of cluster centers $k$ is. It largely depends on the distribution of our data and on the number of dimensions we use. In the following, we will estimate unvalidated Markov models using different numbers of cluster centers and use the VAMP-2 score as a heuristics. This approach requires us to guess the MSM lag time, which we set to the TICA lag time of $5$ steps (or $0.5$ ns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clustercenters = [5, 10, 75, 350]\n",
    "scores = np.zeros((len(n_clustercenters), 20))\n",
    "for n, k in enumerate(n_clustercenters):\n",
    "    _cl = pyemma.coordinates.cluster_kmeans(tica_output, k=k, max_iter=50, stride=10, fixed_seed=True)\n",
    "    _msm = pyemma.msm.estimate_markov_model(_cl.dtrajs, 5)\n",
    "    scores[n] = _msm.score_cv(_cl.dtrajs, n=20, score_method='VAMP2', score_k=min(10, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "lower, upper = pyemma.util.statistics.confidence_interval(scores.T.tolist(), conf=1)\n",
    "ax.fill_between(n_clustercenters, lower, upper, alpha=.3)\n",
    "ax.plot(n_clustercenters, np.mean(scores, axis=1), 'o-')\n",
    "ax.semilogx()\n",
    "ax.set_xlabel('# cluster centers')\n",
    "ax.set_ylabel('VAMP-2 scores');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the VAMP-2 score is already saturated at $75$ states. We will use this number for further analysis.\n",
    "\n",
    "As already stated above, the score has been generated using MSMs that were not validated, meaning that the above plot is really just a heuristics. Besides having an optimal score, we want to obtain a robust model that describe physically interesting states. Thus, the number of states $k$ is often re-adjusted after model inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster = pyemma.coordinates.cluster_kmeans(tica_output, k=75, max_iter=50, stride=10, fixed_seed=True)\n",
    "dtrajs_concatenated = np.concatenate(cluster.dtrajs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that discretization is a stochastic procedure and, hence, individual runs might yield different results. In order to have congruent results with the interpretations for each run in this example, we are fixing the random seed (not advised in general). \n",
    "\n",
    "We can check the location of our discrete states by plotting them onto the density of our data in the first two TICA dimensions. The cluster centers are contained in the `cluster` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "pyemma.plots.plot_density(*tica_concatenated.T[:2], ax=ax, cbar=False, alpha=0.3)\n",
    "ax.scatter(*cluster.clustercenters.T[:2], s=5, c='C1')\n",
    "ax.set_xlabel('IC 1')\n",
    "ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the states are well distributed in TICA space.\n",
    "\n",
    "### MSM estimation and validation\n",
    "\n",
    "The first validation that is usually done when estimating a Markov model is the estimation of implied timescales (ITS) $t_i$. They are computed from the eigenvalues of the Markov transition matrix $\\lambda_i$ by\n",
    "$$\n",
    "t_i = -\\frac{\\tau}{\\ln|\\lambda_i(\\tau)|}\n",
    "$$\n",
    "\n",
    "with $\\tau$ being the lag time. The ITS $t_i$ describes the decorrelation time of the $i$-th process which is independent of the  hyper-parameter $\\tau$. Thus, we look for ITS convergence and chose $\\tau$ accordingly. Please note that the lagtime also represents the time resolution limit of the estimated Markov model.\n",
    "\n",
    "Now, we calculate the ITS with `pyemma.msm.its()` up to a lagtime of $50$ steps, which is equivalent to $5\\,\\mathrm{ns}$ for this dataset ($\\Delta t=0.1\\,\\mathrm{ns}$). The uncertainty of the implied timescales is quantified based upon Markov models sampled according to a Bayesian scheme. If this this is too time-consuming maximum likelihood MSMs can be used instead, by setting the errors keyword argument to `None`.\n",
    "\n",
    "Please note that instead of a single number `lags=50`, an array can be passed to compute the ITS at defined lagtimes. When we pass an integer ($K$) as this value a set of lag times starting from $\\Delta t$ to $K\\Delta t$ will be generated, using a multiplier of 1.5 between successive lag-times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = pyemma.msm.its(cluster.dtrajs, lags=50, nits=10, errors='bayes')\n",
    "pyemma.plots.plot_implied_timescales(its, units='ns', dt=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solid lines correspond to the ITS of maximum likelihood MSMs. The confidence intervals are depicted by the shaded areas. They contain 95% of the samples generated by the Bayesian MSM; the sample means are given by dashed lines.\n",
    "\n",
    "The implied timescales converge quickly. Above $0.5$ ns, the implied timescales of the slowest processes are constant within error. We thus select a lag time of $5$ steps ($0.5$ ns) to build a Markov model. As a quick check we print the fraction of states and counts that are in the active set. \n",
    "\n",
    "Please note the similarity of the `msm` object to the `tica` object. Both are estimator instances and contain all the relevant information from the estimation and methods for validation and further analysis. \n",
    "\n",
    "In order to keep track of our trajectory time step, a `dt_traj` keyword argument can be passed that contains the trajectory time step unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.bayesian_markov_model(cluster.dtrajs, lag=5, dt_traj='0.1 ns')\n",
    "print('fraction of states used = {:.2f}'.format(msm.active_state_fraction))\n",
    "print('fraction of counts used = {:.2f}'.format(msm.active_count_fraction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is validated with a Chapman-Kolmogorov test. It compares the right and the left side of the Chapman-Kolmogorov equation\n",
    "\n",
    "$$\n",
    "T(k \\tau) = T^k(\\tau)\n",
    "$$\n",
    "\n",
    "with $T$ being the transition matrix. `PyEMMA` automatically estimates a new MSM transition matrix at lagtime $k \\tau$ and propagates the original transition matrix by the $k$-th power. The highest $k$ can be adjusted using the `mlags` keyword argument of `msm.cktest()`.\n",
    "\n",
    "Since we can only inspect the result for a small number of (macro-) states, we use the implied timescales plot as a heuristics to estimate a number of metastable states to test for. We can resolve $3$ slow processes up to lagtimes of $5$ ns. Since the Chapman-Kolmogorov test involves estimations at higher lagtimes, we will attempt to capture those processes choosing  $4$ metastable states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstates = 4\n",
    "cktest = msm.cktest(nstates)\n",
    "pyemma.plots.plot_cktest(cktest, dt=0.1, units='ns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming $4$ metastable states yields a passing Chapman-Kolmogorov test.\n",
    "\n",
    "### MSM spectral analysis and PCCA\n",
    "\n",
    "From the MSM object `msm`, various properties can be obtained. We start the spectral analysis by examining the implied timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nits = 15\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "def its_separation_err(ts, ts_err):\n",
    "    \"\"\"\n",
    "    Error propagation from ITS standard deviation to timescale separation\n",
    "    \"\"\"\n",
    "    return ts[:-1] / ts[1:] * np.sqrt((ts_err[:-1] / ts[:-1])**2 + (ts_err[1:]/ts[1:])**2)\n",
    "\n",
    "axes[0].errorbar(range(1, nits+1), \n",
    "                 msm.timescales(k=nits), \n",
    "                 yerr=msm.sample_std('timescales', nits), \n",
    "                 fmt='.', markersize=10)\n",
    "axes[1].errorbar(range(1, nits), \n",
    "                 msm.timescales(k = nits)[:-1]/msm.timescales(k = nits)[1:], \n",
    "                 yerr=its_separation_err(msm.timescales(k = nits), \n",
    "                                         msm.sample_std('timescales', k=nits)), \n",
    "                 fmt='.', \n",
    "                 markersize=10,\n",
    "                 color='C0')\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_xticks(range(1, nits+1))\n",
    "    ax.grid(True, axis='x', linestyle=':')\n",
    "\n",
    "axes[0].axhline(msm.lag * 0.1, lw=1.5, color='k')\n",
    "axes[0].axhspan(0, msm.lag * 0.1, alpha=.3, color='k')\n",
    "\n",
    "axes[0].set_xlabel('implied timescale index')\n",
    "axes[0].set_ylabel('implied timescales / ns')\n",
    "\n",
    "axes[1].set_xticks(range(1, nits))\n",
    "axes[1].set_xticklabels([\"{:d}/{:d}\".format(k, j) for k,j in zip(range(1,nits+2), range(2,nits+1))], rotation=45)\n",
    "axes[1].set_xlabel('implied timescale indices')\n",
    "axes[1].set_ylabel('relative timescale separation')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, `PyEMMA` sorts the implied timescales (and their corresponding eigenfunctions) in descending order. From the time-scale fraction we can see that the largest time-scale gap, within the time-resolution of the model, is between the 3rd and 4th process, suggesting that $4$ meta-stable states may be a good choice for coarse-graining. We discuss this further below.\n",
    "\n",
    "We go on by analyzing the stationary distribution and the free energy computed over the first two TICA coordinates. The stationary distribution, $\\pi$, is stored in `msm.pi` or  (as an alias) `msm.stationary_distribution`. We compute the free energy landscape by re-weighting the trajectory frames with stationary probabilities from the MSM (returned by  `msm.trajectory_weights()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharex=True, sharey=True)\n",
    "pyemma.plots.plot_contour(\n",
    "    *tica_concatenated.T[:2],\n",
    "    msm.pi[dtrajs_concatenated],\n",
    "    ax=axes[0],\n",
    "    mask=True,\n",
    "    cbar_label='stationary distribution')\n",
    "pyemma.plots.plot_free_energy(\n",
    "    *tica_concatenated.T[:2],\n",
    "    weights=np.concatenate(msm.trajectory_weights()),\n",
    "    ax=axes[1],\n",
    "    legacy=False)\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('IC 1')\n",
    "axes[0].set_ylabel('IC 2')\n",
    "axes[0].set_title('Stationary distribution', fontweight='bold')\n",
    "axes[1].set_title('Reweighted free energy surface', fontweight='bold')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors corresponding to the slowest processes (largest implied time-scales) contain information about what configurational changes are happening on what time-scales. We analyze the slowest processes by inspecting the value of the first four eigenfunctions projected on two the first TICA coordinates. As the first right eigenvector corresponds to the stationary process (equilibrium) it is constant at $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvec = msm.eigenvectors_right()\n",
    "print('The first eigenvector is one: {} (min={}, max={})'.format(\n",
    "    np.allclose(eigvec[:, 0], 1, atol=1e-15), eigvec[:, 0].min(), eigvec[:, 0].max()))\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pyemma.plots.plot_contour(\n",
    "        *tica_concatenated.T[:2],\n",
    "        eigvec[dtrajs_concatenated, i + 1],\n",
    "        ax=ax,\n",
    "        cmap='PiYG',\n",
    "        cbar_label='{}. right eigenvector'.format(i + 2),\n",
    "        mask=True)\n",
    "    ax.set_xlabel('IC 1')\n",
    "axes[0].set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvector of the MSM contain information about what conformational changes are happening on a certain timescale, governed by the correponding implied timescale. Specifically, conformational states in areas of configuration space at negative-values for a given eigenvector, exchange with corresponding positive regions for the same eigenvector. The relaxation timescale of this exchange process is exactly the implied timescale. Since the eigenvectors were internally sorted according to their eigenvalue, they correspond to the four slowest processes of the implied timescale plot. We see that indeed, the slowest processes occur inbetween the dense clusters in the TICA projection.\n",
    "\n",
    "Next, we do a PCCA++ coarse graining into a user defined number of macrostates. As already discussed, $4$ is a good choice for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm.pcca(nstates);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCCA++ algorithm computes the so called memberships, i.e. the probability of each microstate to belong to a given macrostate. In other words, PCCA++ does a fuzzy assignment of the microstates to macrostates which is encoded in the memberships. We can visualize the $4$ membership distributions over the first $2$ TICA dimensions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, msm.n_metastable, figsize=(15, 3), sharex=True, sharey=True)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pyemma.plots.plot_contour(\n",
    "        *tica_concatenated.T[:2],\n",
    "        msm.metastable_distributions[i][dtrajs_concatenated],\n",
    "        ax=ax,\n",
    "        cmap='afmhot_r', \n",
    "        mask=True,\n",
    "        method='nearest',\n",
    "        cbar_label='metastable distribution {}'.format(i))\n",
    "    ax.set_xlabel('IC 1')\n",
    "axes[0].set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the membership probabilities roughly match to the basins of the free energy landscape presented above.\n",
    "\n",
    "In some cases, it might be useful to convert these distributions into crisp assignments. This can be computed by taking the argmax of each microstate's memberships to the macrostates. They are contained in `msm.metastable_assignments`. Let's see what this looks like in the first two TICA projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "metastable_traj = msm.metastable_assignments[dtrajs_concatenated]\n",
    "\n",
    "pyemma.plots.plot_state_map(\n",
    "    *tica_concatenated.T[:2], metastable_traj, ax=ax, zorder=-1)\n",
    "\n",
    "ax.set_xlabel('IC 1')\n",
    "ax.set_ylabel('IC 2')\n",
    "ax.set_xlim(-2, 8)\n",
    "ax.set_ylim(-2, 8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could expect from the membership probabilities, PCCA++ has nicely separated our state space in the first two TICA components. \n",
    "\n",
    "At this point, we usually want to investigate what molecular structures the identified metastable structures correspond to. We generate a number of representative sample structures for each macrostate and store them into a trajectory file for visual inspection. The following cell writes trajectory files to hard disc. They can be loaded and analyzed with external software packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcca_samples = msm.sample_by_distributions(msm.metastable_distributions, 10)\n",
    "torsions_source = pyemma.coordinates.source(files, features=torsions_feat)\n",
    "pyemma.coordinates.save_trajs(\n",
    "    torsions_source,\n",
    "    pcca_samples,\n",
    "    outfiles=['./data/pcca{}_10samples.pdb'.format(n) for n in range(msm.n_metastable)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one can visualize the structures in this notebook with NGLView. For this, we need to provide a custom function that defines the representations of our molecule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_metastable(samples, cmap, selection='not element H'):\n",
    "    \"\"\" visualize metastable states\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples: list of mdtraj.Trajectory objects\n",
    "        each element contains all samples for one metastable state.\n",
    "    cmap: matplotlib.colors.ListedColormap\n",
    "        color map used to visualize metastable states before.\n",
    "    selection: str\n",
    "        which part of the molecule to selection for visualization. For details have a look here:\n",
    "        http://mdtraj.org/latest/examples/atom-selection.html#Atom-Selection-Language\n",
    "    \"\"\"\n",
    "    import nglview\n",
    "    from matplotlib.colors import to_hex\n",
    "\n",
    "    widget = nglview.NGLWidget()\n",
    "    widget.clear_representations()\n",
    "    ref = samples[0]\n",
    "    for i, s in enumerate(samples):\n",
    "        s = s.superpose(ref)\n",
    "        s = s.atom_slice(s.top.select(selection))\n",
    "        comp = widget.add_trajectory(s)\n",
    "        comp.add_licorice()\n",
    "\n",
    "    # this has to be done in a separate loop for whatever reason...\n",
    "    x = np.linspace(0, 1, num=len(samples))\n",
    "    for i, x_ in enumerate(x):\n",
    "        c = to_hex(cmap(x_))\n",
    "        widget.update_licorice(color=c, component=i, repr_index=i)\n",
    "        widget.remove_cartoon(component=i)\n",
    "    return widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to saving the trajectories to disc, we now create a list with `mdtraj.Trajectory` objects that contain samples of our metastable structures. They are visualized with NGLView as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_samples = [pyemma.coordinates.save_traj(files, idist, outfile=None, top=pdb)\n",
    "              for idist in msm.sample_by_distributions(msm.metastable_distributions, 50)]\n",
    "\n",
    "cmap = mpl.cm.get_cmap('viridis', nstates)\n",
    "visualize_metastable(my_samples, cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This coarse-grained representation of the dynamics is more directly amenable to human interpretation. Nevertheless, as for the conventional MSM, we can still compute several interesting properties. We start with the stationary distribution which encodes the free energy of the states. This can be achieved by summing all the  contributions to a coarse-grained state $\\mathcal{S}_i$:\n",
    "$$\n",
    "G_i = - k_b T \\ln(\\sum_{j\\in \\mathcal{S}_i} \\pi_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('state\\tÏ€\\t\\tG/kT')\n",
    "for i, s in enumerate(msm.metastable_sets):\n",
    "    p = msm.pi[s].sum()\n",
    "    print('{}\\t{:f}\\t{:f}'.format(i, p, -np.log(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing PCCA metastable states, we can also extract mean first passage times (MFPTs) and transition rates between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "mfpt = np.zeros((nstates, nstates))\n",
    "mfpt_err = np.zeros((nstates, nstates))\n",
    "for i, j in product(range(nstates), repeat = 2):\n",
    "    mfpt[i, j] = msm.mfpt(\n",
    "        msm.metastable_sets[i],\n",
    "        msm.metastable_sets[j])\n",
    "    mfpt_err[i, j] = msm.sample_std('mfpt', msm.metastable_sets[i], msm.metastable_sets[j])\n",
    "\n",
    "from pandas import DataFrame\n",
    "print('MFPT (ns):')\n",
    "DataFrame(np.array(['{:.1f} Â± {:05.1f}'.format(a, b) for a, b in zip(mfpt.flat, mfpt_err.flat)]).reshape(nstates, nstates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition path theory\n",
    "Further, the flux between metastable states can be computed and coarse grained as follows. We chose metastable states $4$ and $3$ as an example between which the flux is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, final = 1, 2\n",
    "A = msm.metastable_sets[start]\n",
    "B = msm.metastable_sets[final]\n",
    "flux = pyemma.msm.tpt(msm, A, B)\n",
    "\n",
    "cg, cgflux = flux.coarse_grain(msm.metastable_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The committor as projected in the first two TICA dimensions can be displayed with a filled contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "pyemma.plots.plot_contour(\n",
    "    *tica_concatenated.T[:2], flux.committor[np.concatenate(cluster.dtrajs)], cmap='brg', ax=ax,\n",
    "    mask=True, method='nearest', cbar_label=r'committor {} $\\to$ {}'.format(start, final))\n",
    "\n",
    "ax.set_xlim(-2, 8)\n",
    "ax.set_ylim(-2, 8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the committor is constant within the metastable sets defined above. Transition regions can be identified by committor values $\\tilde{} 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing experimental observables\n",
    "\n",
    "Having thoroughly constructed, validated and analysed our MSM above, we may want to take the next step and compare our model to experimental data. `PyEMMA` enables computation of stationary as well as dynamic experimental observables, below we give give some examples of this. We will make use of some external library functionality provided by `MDTraj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdtraj import shrake_rupley, compute_rg\n",
    "\n",
    "#We compute a maximum likelihood MSM for comparison\n",
    "mlmsm = pyemma.msm.estimate_markov_model(cluster.dtrajs, lag=5, dt_traj='0.1 ns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pre-compute the experimental observables in the following cell. When we invoke **save_traj** to obtain structures for our samples, we should create a reader - otherwise the reader will be created again internally in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pyemma.coordinates.source(files, top=pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_samples = [smpl for smpl in msm.sample_by_state(20)]\n",
    "_samples = [pyemma.coordinates.save_traj(\n",
    "    reader, smpl, outfile=None, top=pdb) for smpl in markov_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have molecular structures for all of micro states. For these we are going to compute two different observables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_sasa_all = [shrake_rupley(sample, mode='residue')\n",
    "                   for sample in _samples]\n",
    "markov_rg_all = [compute_rg(sample) for sample in _samples]\n",
    "\n",
    "markov_average_trp_sasa = np.array(markov_sasa_all).mean(axis=1)[:, 0]\n",
    "markov_average_rg = np.array(markov_rg_all).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius of gyration\n",
    "The radius of gyration $r^2_g(x)$ is a measure of the over-all dimensions of a particles in configuration, $x$. It is a quantity often extracted extracted from light-scattering experiments. In the context of proteins and nucleic acids these experiments often happen on bulk samples and the observables is therefore stationary and averaged by the Boltzmann distribution:\n",
    "$$ \n",
    " R_{g, \\mathrm{obs}}^2 = \\mathcal{Z}^{-1}\\int_{\\Omega} \\mathrm{d}x\\, r_g(x) \\exp{(-\\frac{E(x)}{kT})}.\n",
    "$$\n",
    "This value is also called the _expectation value of $r^2_g(x)$ with respect to the Boltzmann distribution_. Since we have access to the stationary distribution from the Markov model we can approximate this continuous integral by the sum:\n",
    "\n",
    "$$\n",
    " R_{g, \\mathrm{obs}}^2 \\approx \\sum_i \\pi_i \\mathbf{r^2_g}_i \n",
    "$$\n",
    "with\n",
    "$$ \\mathbf{r^2_g}_i  = \\frac{1}{\\pi_i\\mathcal{Z}} \\int_{x\\in S_i} \\mathrm{d}x\\, r^2_g(x)\\exp(-\\beta E(x)). $$\n",
    "The last expression constitutes the average of the experimental observable ($r^2_g(x)$) confined to each of our Markov states individually.\n",
    "\n",
    "Above we pre-computed the vector $\\mathbf{r^2_g}=\\{\\mathbf{r^2_g}_i\\}$ as `markov_average_rg`. Using this vector and our estimated Markov model we can compute the expectation value using the `expectation` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The average radius of gyration of penta-peptide is {:.3f} nm\".format(msm.expectation(markov_average_rg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a Bayesian MSM estimated we can also compute the uncertainty in our prediction of the observable as standard deviations or confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The standard deviation of our prediction of the average radius of gyration of penta-peptide is {:.9f} nm\".format(msm.sample_std('expectation', markov_average_rg)))\n",
    "print(\"The {:d}% CI of our prediction of the average radius of gyration of penta-peptide have the bounds ({:.5f}, {:.5f})\".format(int(msm.conf*100), *msm.sample_conf('expectation', markov_average_rg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our model is very confident in the prediction of the radius of gyration. However, this does not guarantee it to be accurate -- that is, agree with experimental meaurements. If we lack quantitative agreement with experiments, we can estimate MSMs which optimally balance experimental data and simulation data using the Augmented Markov model (AMM) procedure. A dedicated AMM tutorial can be [found here](http://www.emma-project.org/latest/generated/augmented_markov_model_walkthrough.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Trp-flourescene auto-correlation\n",
    "\n",
    "Fluctuations in the tryptophan flourescence can be measured using spectroscopic techniques. These fluctuations depend on (among other things) on the solvent accessible surface area (SASA) of tryptophan residues. We will here use a third party library (MDTraj) to estimate the SASA using the Shrake-Rupley algorithm (completed above). Since we are not interested in inspecting the experimental observable as a function of time and since the computation can be expensive to perform for large data-sets we instead sample a representative set of configurations for each of our Markov states. Hint: A similar strategy can be used if expensive external software has to be used to compute the observables including ab initio calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute an auto-correlation function of tryptophan flouresence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_time_ml, eq_acf_ml = mlmsm.correlation(markov_average_trp_sasa, maxtime=15)\n",
    "\n",
    "eq_time_bayes, eq_acf_bayes = msm.sample_mean(\n",
    "    'correlation',\n",
    "    np.array(markov_average_trp_sasa),\n",
    "    maxtime=15)\n",
    "\n",
    "eq_acf_bayes_ci_l, eq_acf_bayes_ci_u = msm.sample_conf(\n",
    "    'correlation',\n",
    "    np.array(markov_average_trp_sasa),\n",
    "    maxtime=15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.plot(eq_time_ml, eq_acf_ml, color='orange', marker='.', label='ML MSM')\n",
    "ax.plot(\n",
    "    eq_time_bayes, eq_acf_bayes, ls='--',marker='x',\n",
    "    color='teal', label='Bayes sample mean')\n",
    "ax.fill_between(\n",
    "    eq_time_bayes, eq_acf_bayes_ci_l[1], eq_acf_bayes_ci_u[1],\n",
    "    color='teal', alpha=0.2, lw=0)\n",
    "ax.semilogx()\n",
    "\n",
    "ax.set_xlim((eq_time_ml[1], eq_time_ml[-1]))\n",
    "ax.set_xlabel(r'time / $\\mathrm{ns}$')\n",
    "ax.set_ylabel(r'Trp-1 SASA ACF / $\\mathrm{nm}^4$')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This amplitude is likely too small to be experimentally measurable if we consider experimental uncertainty. Using stopped flow, T-jump, P-jump or other similar experimental setups we can prepare our ensemble in a non-equilibrium initial condition. With `PyEMMA` we can simulate such a scenerio using the `relaxation` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_time_ml, eq_acf_ml = mlmsm.relaxation(\n",
    "    msm.metastable_distributions[0],\n",
    "    markov_average_trp_sasa,\n",
    "    maxtime=15)\n",
    "\n",
    "eq_time_bayes, eq_acf_bayes = msm.sample_mean(\n",
    "    'relaxation',\n",
    "    msm.metastable_distributions[0],\n",
    "    np.array(markov_average_trp_sasa),\n",
    "    maxtime=15)\n",
    "\n",
    "eq_acf_bayes_CI_l, eq_acf_bayes_CI_u = msm.sample_conf(\n",
    "    'relaxation', \n",
    "    msm.metastable_distributions[0],\n",
    "    np.array(markov_average_trp_sasa),\n",
    "    maxtime=15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.semilogx(eq_time_ml, eq_acf_ml, color='orange', marker='^', label='ML MSM')\n",
    "ax.plot(\n",
    "    eq_time_bayes, eq_acf_bayes, ls='--',\n",
    "    color='teal', label='Bayes sample mean')\n",
    "ax.fill_between(\n",
    "    eq_time_bayes, eq_acf_bayes_CI_l[1], eq_acf_bayes_CI_u[1],\n",
    "    color='teal', alpha=0.2, lw=0)\n",
    "ax.semilogx()\n",
    "\n",
    "ax.set_xlim((eq_time_ml[1], eq_time_ml[-1]))\n",
    "ax.set_xlabel(r'time / $\\mathrm{ns}$')\n",
    "ax.set_ylabel(r'Average Trp-1 SASA / $\\mathrm{nm}^2$')\n",
    "\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import LogLocator\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "mpl.rcParams['axes.titlesize'] = 8\n",
    "mpl.rcParams['axes.labelsize'] = 8\n",
    "mpl.rcParams['font.size'] = 8\n",
    "mpl.rcParams['legend.fontsize'] = 5\n",
    "mpl.rcParams['xtick.labelsize'] = 5\n",
    "mpl.rcParams['ytick.labelsize'] = 5\n",
    "mpl.rcParams['xtick.minor.pad'] = 3\n",
    "mpl.rcParams['xtick.major.pad'] = 3\n",
    "mpl.rcParams['ytick.minor.pad'] = 3\n",
    "mpl.rcParams['ytick.major.pad'] = 3\n",
    "mpl.rcParams['axes.labelpad'] = 1\n",
    "mpl.rcParams['lines.markersize'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.47, 4))\n",
    "gw = int(np.floor(0.5 + 1000 * fig.get_figwidth()))\n",
    "gh = int(np.floor(0.5 + 1000 * fig.get_figheight()))\n",
    "gs = plt.GridSpec(gh, gw)\n",
    "gs.update(hspace=0.0, wspace=0.0, left=0.0, right=1.0, bottom=0.0, top=1.0)\n",
    "\n",
    "ax_box = fig.add_subplot(gs[:, :])\n",
    "ax_box.set_axis_off()\n",
    "ax_box.text(0.00, 0.97, '(a)', size=10)\n",
    "ax_box.text(0.00, 0.55, '(b)', size=10)\n",
    "ax_box.text(0.55, 0.97, '(c)', size=10)\n",
    "ax_box.text(0.00, 0.30, '(d)', size=10)\n",
    "\n",
    "ax_feat = fig.add_subplot(gs[200:1300, 400:1800])\n",
    "ax_feat.bar(vamp_bars_plot['labels'], vamp_bars_plot['scores'], 0.5)\n",
    "ax_feat.tick_params(axis='x', labelrotation=35)\n",
    "ax_feat.set_ylabel('VAMP2 score')\n",
    "ax_feat.set_title(r'lag time $\\tau$={:.1f}ns'.format(vamp_bars_plot['lag'] * 0.1))\n",
    "\n",
    "ax_density = fig.add_subplot(gs[400:1550, 2200:3350])\n",
    "_, _, misc = pyemma.plots.plot_density(\n",
    "    *tica_concatenated.T[:2],\n",
    "    ax=ax_density,\n",
    "    cax=fig.add_subplot(gs[300:350, 2200:3350]),\n",
    "    cbar_orientation='horizontal',\n",
    "    logscale=True)\n",
    "misc['cbar'].set_ticks(LogLocator(base=10.0))\n",
    "misc['cbar'].ax.xaxis.set_ticks_position('top')\n",
    "misc['cbar'].ax.xaxis.set_label_position('top')\n",
    "ax_density.set_xlabel('IC 1')\n",
    "ax_density.set_ylabel('IC 2')\n",
    "\n",
    "x = 0.1 * np.arange(tica_output[0].shape[0])\n",
    "ax_tic1 = fig.add_subplot(gs[1850:2200, 400:3350])\n",
    "ax_tic2 = fig.add_subplot(gs[2200:2550, 400:3350])\n",
    "\n",
    "ax_tic1.plot(x, tica_output[0][:, 0])\n",
    "ax_tic2.plot(x, tica_output[0][:, 1])\n",
    "ax_tic1.set_ylabel('IC 1')\n",
    "ax_tic2.set_ylabel('IC 2')\n",
    "ax_tic2.set_xlabel('time / ns')\n",
    "\n",
    "ax_its = fig.add_subplot(gs[2870:3670, 400:3350])\n",
    "pyemma.plots.plot_implied_timescales(its, units='ns', dt=0.1, ax=ax_its, nits=4, ylog=False)\n",
    "ax_its.set_ylim(1, 15)\n",
    "ax_its.set_xlabel(r'lag time $\\tau$ / ns')\n",
    "\n",
    "fig.savefig('figure_1.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = pyemma.plots.plot_cktest(cktest, figsize=[3.47, 3.47], dt=0.1, units='ns')\n",
    "for ax in axes[-1, :]:\n",
    "    ax.set_xlabel(r'$\\tau$ / ns')\n",
    "for ax in axes[:, 0]:\n",
    "    ax.set_ylabel('prob.')\n",
    "fig.savefig('figure_2.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3.47, 4))\n",
    "gw = int(np.floor(0.5 + 1000 * fig.get_figwidth()))\n",
    "gh = int(np.floor(0.5 + 1000 * fig.get_figheight()))\n",
    "gs = plt.GridSpec(gh, gw)\n",
    "gs.update(hspace=0.0, wspace=0.0, left=0.0, right=1.0, bottom=0.0, top=1.0)\n",
    "\n",
    "ax_box = fig.add_subplot(gs[:, :])\n",
    "ax_box.set_axis_off()\n",
    "ax_box.text(0.00, 0.97, '(a)', size=10)\n",
    "ax_box.text(0.52, 0.97, '(b)', size=10)\n",
    "ax_box.text(0.00, 0.50, '(c)', size=10)\n",
    "ax_box.text(0.52, 0.50, '(d)', size=10)\n",
    "\n",
    "ax_fe = fig.add_subplot(gs[400:1750, 400:1750])\n",
    "_, _, misc = pyemma.plots.plot_free_energy(\n",
    "    *tica_concatenated.T[:2],\n",
    "    weights=np.concatenate(msm.trajectory_weights()),\n",
    "    ax=ax_fe,\n",
    "    cax=fig.add_subplot(gs[300:350, 400:1750]),\n",
    "    cbar_orientation='horizontal',\n",
    "    legacy=False)\n",
    "misc['cbar'].set_ticks(np.linspace(0, 8, 5))\n",
    "misc['cbar'].ax.xaxis.set_ticks_position('top')\n",
    "misc['cbar'].ax.xaxis.set_label_position('top')\n",
    "ax_fe.set_ylabel('IC 2')\n",
    "ax_fe.set_xticklabels([])\n",
    "\n",
    "ax_state = fig.add_subplot(gs[400:1750, 2000:3350])\n",
    "_, _, misc = pyemma.plots.plot_state_map(\n",
    "    *tica_concatenated.T[:2],\n",
    "    metastable_traj,\n",
    "    ax=ax_state,\n",
    "    cax=fig.add_subplot(gs[300:350, 2000:3350]),\n",
    "    cbar_label='metastable state',\n",
    "    cbar_orientation='horizontal')\n",
    "misc['cbar'].ax.xaxis.set_ticks_position('top')\n",
    "misc['cbar'].ax.xaxis.set_label_position('top')\n",
    "ax_state.set_xticklabels([])\n",
    "ax_state.set_yticklabels([])\n",
    "\n",
    "evec_idx = 1\n",
    "ax_eig = fig.add_subplot(gs[2300:3650, 400:1750], zorder=1)\n",
    "_, _, misc = pyemma.plots.plot_contour(\n",
    "    *tica_concatenated.T[:2],\n",
    "    eigvec[dtrajs_concatenated, evec_idx],\n",
    "    cmap='PiYG',\n",
    "    ax=ax_eig,\n",
    "    mask=True,\n",
    "    cax=fig.add_subplot(gs[2200:2250, 400:1750]),\n",
    "    cbar_label='{}. right eigenvector'.format(evec_idx + 1),\n",
    "    cbar_orientation='horizontal')\n",
    "misc['cbar'].set_ticks(np.linspace(*misc['cbar'].get_clim(), 3))\n",
    "misc['cbar'].ax.xaxis.set_ticks_position('top')\n",
    "misc['cbar'].ax.xaxis.set_label_position('top')\n",
    "ax_eig.set_xlabel('IC 1')\n",
    "ax_eig.set_ylabel('IC 2')\n",
    "\n",
    "ax_flux = fig.add_subplot(gs[2300:3650, 2000:3350], zorder=1)\n",
    "_, _, misc = pyemma.plots.plot_contour(\n",
    "    *tica_concatenated.T[:2],\n",
    "    flux.committor[np.concatenate(cluster.dtrajs)],\n",
    "    cmap='brg',\n",
    "    ax=ax_flux,\n",
    "    mask=True,\n",
    "    cax=fig.add_subplot(gs[2200:2250, 2000:3350]),\n",
    "    cbar_label=r'committor {} $\\to$ {}'.format(start, final),\n",
    "    cbar_orientation='horizontal')\n",
    "misc['cbar'].set_ticks(np.linspace(0, 1, 3))\n",
    "misc['cbar'].set_ticklabels(['start', 'transition state', 'final'])\n",
    "misc['cbar'].ax.xaxis.set_ticks_position('top')\n",
    "misc['cbar'].ax.xaxis.set_label_position('top')\n",
    "ax_flux.set_xlabel('IC 1')\n",
    "ax_flux.set_yticklabels([])\n",
    "\n",
    "fig.savefig('figure_3.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
