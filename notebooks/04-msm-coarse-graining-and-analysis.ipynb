{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - MSM coarse graining and analysis\n",
    "In this notebook, we will cover how to coarse grain an MSM onto the metastable states and analyze the modelled process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import mdshare\n",
    "import pyemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: preprocessed, two-dimensional data (toy model)\n",
    "We load the two-dimensional trajectory from an archive using `numpy`, directly discretize the full space using $k$-means clustering, visualize the marginal and joint distributions of both components as well as the cluster centers, and show the implied timescale (ITS) convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = mdshare.fetch('hmm-doublewell-2d-100k.npz', working_directory='data')\n",
    "with np.load(file) as fh:\n",
    "    data = fh['trajectory']\n",
    "\n",
    "cluster = pyemma.coordinates.cluster_kmeans(data, k=50, max_iter=50)\n",
    "its = pyemma.msm.its(cluster.dtrajs, lags=[1, 2, 3, 5, 7, 10], nits=3, errors='bayes')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "pyemma.plots.plot_feature_histograms(data, feature_labels=['$x$', '$y$'], ax=axes[0])\n",
    "pyemma.plots.plot_density(*data.T, ax=axes[1], cbar=False, alpha=0.1)\n",
    "axes[1].scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "axes[1].set_xlabel('$x$')\n",
    "axes[1].set_ylabel('$y$')\n",
    "pyemma.plots.plot_implied_timescales(its, ylog=False, ax=axes[2])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, let's have a look at the implied timescales error bars. They were computed from a Bayesian MSM, as requested by the `errors='bayes'` argument of the `pyemma.msm.its()` function. As mentioned before, Bayesian MSMs incorporate a sample of transition matrices. Target properties such as implied timescales can now simply be computed from the individual matrices. Thereby, the posterior distributions of these properties can be estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_msm = pyemma.msm.bayesian_markov_model(cluster.dtrajs, lag=1, conf=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any PyEMMA method that derives target properties from MSMs, sample mean and confidence intervals (as defined by the function argument above) are directly accessible with  `sample_mean()` and `sample_conf()`. Further, `sample_std()` is available for computing the standard deviation. In the more general case, it might be interesting to extract the full sample of a function evaluation with `sample_f()`. The syntax is equivalent for all those functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = bayesian_msm.sample_mean('timescales', k=1)\n",
    "sample_conf_L, sample_conf_R = bayesian_msm.sample_conf('timescales', k=1)\n",
    "\n",
    "print('Mean of first ITS: {}'.format(sample_mean))\n",
    "print('Confidence interval: {}, {}'.format(sample_conf_L, sample_conf_R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that sample mean and maximum likelihood estimates are not identical and generally do not provide numerically identical results.\n",
    "\n",
    "Now, for the sake of simplicity we proceed with the analysis of a maximum likelihood MSM. We estimate it at lag time $1$ step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(cluster.dtrajs, lag=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check for disconnectivity. The MSM is constructed on the largest set of discrete states that are (reversibly) connected and the `active_state_fraction` and `active_count_fraction` show us the fraction of discrete states and transition counts from our data which are part of this largest set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fraction of states used = {:f}'.format(msm.active_state_fraction))\n",
    "print('fraction of counts used = {:f}'.format(msm.active_count_fraction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraction is, in both cases, $1$ and, thus, we have no disconnected states (which we would have to exclude from our analysis).\n",
    "\n",
    "If there would have been any disconnectivity in our data (fractions $<1$), we can access the indices of the **active states** (members of the largest connected set) via the `active_set` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msm.active_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this potential issue out of the way, we can extract our first (stationary/thermodynamic) property, the `stationary_distribution` or `pi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msm.stationary_distribution)\n",
    "print('msm.stationary_distribution is msm.pi: {}'.format(\n",
    "    np.all(msm.stationary_distribution == msm.pi)))\n",
    "print('sum of weights = {:f}'.format(msm.pi.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `msm.pi` tells us, for each discrete state, the absolute probability of observing said state in global equilibrium. Mathematically speaking, the stationary distribution $\\pi$ is the left eigenvector of the transition matrix $\\mathbf{T}$ to the eigenvalue $1$:\n",
    "\n",
    "$$\\pi^\\top \\mathbf{T} = \\pi^\\top.$$\n",
    "\n",
    "We can use the stationary distribution to, e.g., visualize the weight of the dicrete states and, thus, to highlight which areas of our feature space are most probable. Here, we show all data points in a two dimensional scatter plot and color/weight them according to their discrete state membership:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, misc = pyemma.plots.plot_contour(\n",
    "    *data.T, msm.pi[cluster.dtrajs[0]],\n",
    "    cbar_label='stationary distribution',\n",
    "    method='nearest', mask=True)\n",
    "ax.scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stationary distribution can also be used to correct the `pyemma.plots.plot_free_energy()` function in the case where the data points alone are not sufficient to compute the free energy surface by binning, i.e., is the data pints are not sampled from global equilibrium.\n",
    "\n",
    "In this case, we assign the weight of the corresponding discrete state to each data points and pass this information to the plotting function via its `weights` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, misc = pyemma.plots.plot_free_energy(\n",
    "    *data.T,\n",
    "    weights=msm.pi[cluster.dtrajs[0]],\n",
    "    legacy=False)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see further uses of the stationary distribution later. But for now, we continue the analysis of our model by visualizing its (right) eigenvectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvec = msm.eigenvectors_right()\n",
    "print('first eigenvector is one: {} (min={}, max={})'.format(\n",
    "    np.allclose(eigvec[:, 0], 1, atol=1e-15), eigvec[:, 0].min(), eigvec[:, 0].max()))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pyemma.plots.plot_contour(\n",
    "        *data.T, eigvec[cluster.dtrajs[0], i + 1], ax=ax, cmap='PiYG',\n",
    "        cbar_label='{}. right eigenvector'.format(i + 2), mask=True)\n",
    "    ax.scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "    ax.set_xlabel('$x$')\n",
    "axes[0].set_ylabel('$y$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The right eigenvectors can be used to visualize the processes governed by the corresponding implied timescales. The first right eigenvector (always) is $(1,\\dots,1)^\\top$ for an MSM's transition matrix and it corresponds to the stationary process (infinite implied timescale).\n",
    "\n",
    "The second right eigenvector corresponds to the slowest process, and shows negative entries for one group of discrete states and positive values for the other group. This tells us that the slowest process happens between these two groups and it relaxes on the slowest ITS ($\\approx 8.5$ steps).\n",
    "\n",
    "The third and fourth eigenvectors show a larger spread of values and no clear grouping. In combination with the ITS convergence plot, we can safely assume that these eigenvectors contains just noise and do not indicate any resolved processes.\n",
    "\n",
    "We then continue to validate our MSM with a CK test for both metastable states which are already indicated by the second right eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstates = 2\n",
    "pyemma.plots.plot_cktest(msm.cktest(nstates));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently have an MSM with 50 discrete states which has been validated for two metastable states. Using the `coarse_grain()` method, we can obtain an actual two-state MSM by mapping all states within a metastable set into one metastable state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_msm = msm.coarse_grain(nstates)\n",
    "print(coarse_msm.transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the stationary weights of both metastable states by summing the stationary weights of the original MSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('π_0 = {:f}'.format(msm.pi[coarse_msm.metastable_sets[0]].sum()))\n",
    "print('π_1 = {:f}'.format(msm.pi[coarse_msm.metastable_sets[1]].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via the `metastable_assigments` attribute, we can create a trajectory of metastable states. We can then use this trajectory to visualize the metastable state membership for all data points in the original trajectory. Further, we can visualize the coarse-grained MSM using the `pyemma.plots.plot_markov_model()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metastable_traj = coarse_msm.metastable_assignments[cluster.dtrajs[0]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_state_map(*data.T, metastable_traj, ax=axes[0])\n",
    "axes[0].set_xlabel('$x$')\n",
    "axes[0].set_ylabel('$y$')\n",
    "pyemma.plots.plot_markov_model(\n",
    "    coarse_msm,\n",
    "    pos=np.asarray([[0, 0], [3, 2]]),\n",
    "    arrow_curvature=2.0,\n",
    "    figpadding=0.2,\n",
    "    size=12,\n",
    "    ax=axes[1])\n",
    "axes[1].set_aspect('equal')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example of kinetic information is the calculation of mean first passage times (MFPTs). We use the `mfpt()` method of the original MSM object to compute MFPTs between pairs of metastable sets (accessible via the `metastable_sets` attribute of the coarse-grained MSM object). Then, we compute pairwise transition rates (inverse MFPTs) and visualize the kinetic network using the `pyemma.plots.plot_network()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfpt = np.zeros((nstates, nstates))\n",
    "for i in range(nstates):\n",
    "    for j in range(nstates):\n",
    "        mfpt[i, j] = msm.mfpt(\n",
    "            coarse_msm.metastable_sets[i],\n",
    "            coarse_msm.metastable_sets[j])\n",
    "\n",
    "rate = np.zeros_like(mfpt)\n",
    "nz = mfpt.nonzero()\n",
    "rate[nz] = 1.0 / mfpt[nz]\n",
    "\n",
    "pyemma.plots.plot_network(\n",
    "    rate,\n",
    "    pos=np.asarray([[0, 0], [2, 1]]),\n",
    "    arrow_label_format='%.0f steps',\n",
    "    arrow_labels=mfpt,\n",
    "    figpadding=0.3,\n",
    "    size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the arrow thickness is proportional to the transition rates while the arrows' labels show the MFPTs.\n",
    "\n",
    "As described above, the errors can be estimated from the Bayesian MSM. Instead of just printing means and confidence intervals, let's compute the samples explicitely and histogram them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfpt_sample = np.zeros((nstates, nstates, bayesian_msm.nsamples))\n",
    "for i in range(nstates):\n",
    "    for j in range(nstates):\n",
    "        mfpt_sample[i, j] = bayesian_msm.sample_f('mfpt',\n",
    "                                                  coarse_msm.metastable_sets[i],\n",
    "                                                  coarse_msm.metastable_sets[j])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(mfpt_sample[0, 1], histtype='step', label='MS 0 -> MS 1', density=True)\n",
    "ax.hist(mfpt_sample[1, 0], histtype='step', label='MS 1 -> MS 0', density=True)\n",
    "ax.set_xlabel('MFPT (steps)')\n",
    "ax.set_title('Bayesian MFPT sample histograms')\n",
    "fig.legend(loc=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that there is no overlap of the distributions approximated by the Bayesian MSM.\n",
    "\n",
    "## Case 2: low-dimensional molecular dynamics data (alanine dipeptide)\n",
    "We fetch the alanine dipeptide data set, load the backbone torsions into memory, directly discretize the full space using $k$-means clustering, visualize the margial and joint distributions of both components as well as the cluster centers, and show the ITS convergence to help selecting a suitable lag time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('alanine-dipeptide-nowater.pdb', working_directory='data')\n",
    "files = mdshare.fetch('alanine-dipeptide-*-250ns-nowater.dcd', working_directory='data')\n",
    "\n",
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_backbone_torsions()\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "data_all = np.concatenate(data)\n",
    "\n",
    "cluster = pyemma.coordinates.cluster_kmeans(data, k=100, max_iter=50, stride=10)\n",
    "its = pyemma.msm.its(cluster.dtrajs, lags=[1, 2, 5, 10, 20, 50], nits=4, errors='bayes')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "pyemma.plots.plot_feature_histograms(\n",
    "    np.concatenate(data), feature_labels=['$\\Phi$', '$\\Psi$'], ax=axes[0])\n",
    "pyemma.plots.plot_density(*data_all.T, ax=axes[1], cbar=False, alpha=0.1)\n",
    "axes[1].scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "axes[1].set_xlabel('$\\Phi$')\n",
    "axes[1].set_ylabel('$\\Psi$')\n",
    "pyemma.plots.plot_implied_timescales(its, ax=axes[2], units='ps')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then estimate an MSM at lag time $10$ ps and visualize the stationary distribution by coloring all data points according to their discrete state membership and the corresponding stationary weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(cluster.dtrajs, lag=10, dt_traj='0.001 ns')\n",
    "\n",
    "print('fraction of states used = {:f}'.format(msm.active_state_fraction))\n",
    "print('fraction of counts used = {:f}'.format(msm.active_count_fraction))\n",
    "\n",
    "fig, ax, misc = pyemma.plots.plot_contour(\n",
    "    *data_all.T, msm.pi[np.concatenate(cluster.dtrajs)],\n",
    "    cbar_label='stationary_distribution',\n",
    "    method='nearest', mask=True)\n",
    "ax.scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "ax.set_xlabel('$\\Phi$')\n",
    "ax.set_ylabel('$\\Psi$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we visualize the first six right eigenvectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvec = msm.eigenvectors_right()\n",
    "print('first eigenvector is one: {} (min={}, max={})'.format(\n",
    "    np.allclose(eigvec[:, 0], 1, atol=1e-15), eigvec[:, 0].min(), eigvec[:, 0].max()))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pyemma.plots.plot_contour(\n",
    "        *data_all.T, eigvec[np.concatenate(cluster.dtrajs), i + 1], ax=ax, cmap='PiYG',\n",
    "        cbar_label='{}. right eigenvector'.format(i + 2), mask=True)\n",
    "    ax.scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "    ax.set_xlabel('$\\Phi$')\n",
    "    ax.set_ylabel('$\\Psi$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have the $(1,\\dots,1)^\\top$ first right eigenvector of the stationary process.\n",
    "\n",
    "The second to fourth right eigenvectors illustrate the three slowest processes.\n",
    "\n",
    "Eigenvectors five, six, and seven indicate further processes which, however, relax faster than the lag time and cannot be resolved clearly.\n",
    "\n",
    "We now proceed our validation process using the previously estimated Bayesian MSM with four metastable states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstates = 4\n",
    "pyemma.plots.plot_cktest(bayesian_msm.cktest(nstates));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that four metastable states are a reasonable choice for our MSM, we obtain a coarse-grained MSM for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_msm = msm.coarse_grain(nstates)\n",
    "print(coarse_msm.transition_matrix)\n",
    "\n",
    "for i, s in enumerate(coarse_msm.metastable_sets):\n",
    "    print('π_{} = {:f}'.format(i, msm.pi[s].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a small function to visualize samples of metastable states with NGLView."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_metastable(samples, cmap, selection='backbone'):\n",
    "    \"\"\" visualize metastable states\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples: list of mdtraj.Trajectory objects\n",
    "        each element contains all samples for one metastable state.\n",
    "    cmap: matplotlib.colors.ListedColormap\n",
    "        color map used to visualize metastable states before.\n",
    "    selection: str\n",
    "        which part of the molecule to selection for visualization. For details have a look here:\n",
    "        http://mdtraj.org/latest/examples/atom-selection.html#Atom-Selection-Language\n",
    "    \"\"\"\n",
    "    import nglview\n",
    "    from matplotlib.colors import to_hex\n",
    "\n",
    "    widget = nglview.NGLWidget()\n",
    "    widget.clear_representations()\n",
    "    ref = samples[0]\n",
    "    for i, s in enumerate(samples):\n",
    "        s = s.superpose(ref)\n",
    "        s = s.atom_slice(s.top.select(selection))\n",
    "        comp = widget.add_trajectory(s)\n",
    "        comp.add_ball_and_stick()\n",
    "\n",
    "    # this has to be done in a separate loop for whatever reason...\n",
    "    x = np.linspace(0, 1, num=len(samples))\n",
    "    for i, x_ in enumerate(x):\n",
    "        c = to_hex(cmap(x_))\n",
    "        widget.update_ball_and_stick(color=c, component=i, repr_index=i)\n",
    "        widget.remove_cartoon(component=i)\n",
    "    return widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate all three discrete trajectories and obtain a single trajectory of metastable states which we use to visualize the metastable state memberships of all datapoints. We also visualize the coarse-grained MSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metastable_traj = coarse_msm.metastable_assignments[np.concatenate(cluster.dtrajs)]\n",
    "highest_membership = coarse_msm.metastable_distributions.argmax(1)\n",
    "coarse_state_centers = cluster.clustercenters[msm.active_set[highest_membership]]\n",
    "cmap = mpl.cm.get_cmap('viridis', nstates)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "pyemma.plots.plot_state_map(*data_all.T, metastable_traj, ax=ax, alpha=0.5)\n",
    "ax.set_xlabel('$\\Phi$')\n",
    "ax.set_ylabel('$\\Psi$')\n",
    "pyemma.plots.plot_markov_model(\n",
    "    coarse_msm,\n",
    "    pos=coarse_state_centers,\n",
    "    figpadding=0.1,\n",
    "    size=12,\n",
    "    show_frame=True,\n",
    "    ax=ax)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(-np.pi, np.pi)\n",
    "ax.set_ylim(-np.pi, np.pi)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now sample some representative structures and visualize these with the aid of nglview. For the sake of clarity, we draw only the backbone atoms. Since we have obtained several samples for each metastable state, you can click the play button to iterate over all samples. For each iteration the samples of all four states will be drawn.\n",
    "You can double click the molecule to show it at full screen. Press escape to go back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_samples = [pyemma.coordinates.save_traj(files, idist, outfile=None, top=pdb)\n",
    "              for idist in msm.sample_by_distributions(coarse_msm.metastable_distributions, 50)]\n",
    "\n",
    "visualize_metastable(my_samples, cmap, selection='backbone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you noticed how well the metastable state coloring agrees with the eigenvector visualization of the three slowest processes?\n",
    "\n",
    "If we could afford a shorter lag time, we might even be able to resolve more processes and, thus, subdivide the metastable states three (fifth slowest process) and zero (sixth slowest process).\n",
    "\n",
    "Now, we use the `mfpt()` method of the original MSM object to compute MFPTs between pairs of metastable sets and also the pairwise transition rates, and visualize the kinetic network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfpt = np.zeros((nstates, nstates))\n",
    "for i in range(nstates):\n",
    "    for j in range(nstates):\n",
    "        mfpt[i, j] = msm.mfpt(\n",
    "            coarse_msm.metastable_sets[i],\n",
    "            coarse_msm.metastable_sets[j])\n",
    "\n",
    "rate = np.zeros_like(mfpt)\n",
    "nz = mfpt.nonzero()\n",
    "rate[nz] = 1.0 / mfpt[nz]\n",
    "\n",
    "pyemma.plots.plot_network(\n",
    "    rate,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    arrow_label_format='%.1f ns',\n",
    "    arrow_labels=mfpt,\n",
    "    arrow_scale=3.0,\n",
    "    size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Load the heavy atoms' distances into memory, TICA (`lag=3` and `dim=2`), discretize with  100 $k$-means centers and a stride of $10$, and show the ITS convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "feat = #FIXME\n",
    "feat. #FIXME\n",
    "data = #FIXME\n",
    "\n",
    "tica = #FIXME\n",
    "tica_out = #FIXME\n",
    "cluster = #FIXME\n",
    "its = #FIXME\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "pyemma.plots.plot_feature_histograms(tica_out, feature_labels=['IC 1', 'IC 2'], ax=axes[0])\n",
    "pyemma.plots.plot_density(*tica_out.T, ax=axes[1], cbar=False, alpha=0.3)\n",
    "axes[1].scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "axes[1].set_xlabel('IC 1')\n",
    "axes[1].set_ylabel('IC 2')\n",
    "pyemma.plots.plot_implied_timescales(its, ax=axes[2], units='ps')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_distances(feat.select_Heavy())\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "tica = pyemma.coordinates.tica(data, lag=3, dim=2)\n",
    "tica_out = np.concatenate(tica.get_output())\n",
    "cluster = pyemma.coordinates.cluster_kmeans(tica, k=100, max_iter=50, stride=10)\n",
    "its = pyemma.msm.its(cluster.dtrajs, lags=[1, 2, 5, 10, 20, 50], nits=4, errors='bayes')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "pyemma.plots.plot_feature_histograms(tica_out, feature_labels=['IC 1', 'IC 2'], ax=axes[0])\n",
    "pyemma.plots.plot_density(*tica_out.T, ax=axes[1], cbar=False, alpha=0.3)\n",
    "axes[1].scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "axes[1].set_xlabel('IC 1')\n",
    "axes[1].set_ylabel('IC 2')\n",
    "pyemma.plots.plot_implied_timescales(its, ax=axes[2], units='ps')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Estimate an MSM at lag time $10$ ps with `dt_traj='0.001 ns'` and visualize the stationary distribution using a two-dimensional colored scatter plot of all data points in TICA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "msm = #FIXME\n",
    "\n",
    "print('fraction of states used = {:f}'. #FIXME\n",
    "print('fraction of counts used = {:f}'. #FIXME\n",
    "\n",
    "fig, ax, misc = pyemma.plots.plot_contour(\n",
    "    *tica_out.T, msm.pi[np.concatenate(cluster.dtrajs)],\n",
    "    cbar_label='stationary_distribution',\n",
    "    method='nearest', mask=True)\n",
    "ax.scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "ax.set_xlabel('IC 1')\n",
    "ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(cluster.dtrajs, lag=10, dt_traj='0.001 ns')\n",
    "\n",
    "print('fraction of states used = {:f}'.format(msm.active_state_fraction))\n",
    "print('fraction of counts used = {:f}'.format(msm.active_count_fraction))\n",
    "\n",
    "fig, ax, misc = pyemma.plots.plot_contour(\n",
    "    *tica_out.T, msm.pi[np.concatenate(cluster.dtrajs)],\n",
    "    cbar_label='stationary_distribution',\n",
    "    method='nearest', mask=True)\n",
    "ax.scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "ax.set_xlabel('IC 1')\n",
    "ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: now visualize the first six right eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "eigvec = #FIXME\n",
    "print('first eigenvector is one: {} (min={}, max={})'.format( #FIXME\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pyemma.plots.plot_contour( #FIXME\n",
    "    ax.scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "    ax.set_xlabel('IC 1')\n",
    "    ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "eigvec = msm.eigenvectors_right()\n",
    "print('first eigenvector is one: {} (min={}, max={})'.format(\n",
    "    np.allclose(eigvec[:, 0], 1, atol=1e-15), eigvec[:, 0].min(), eigvec[:, 0].max()))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pyemma.plots.plot_contour(\n",
    "        *tica_out.T, eigvec[np.concatenate(cluster.dtrajs), i + 1], ax=ax, cmap='PiYG',\n",
    "        cbar_label='{}. right eigenvector'.format(i + 2), mask=True)\n",
    "    ax.scatter(*cluster.clustercenters.T, s=15, c='C1')\n",
    "    ax.set_xlabel('IC 1')\n",
    "    ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you already guess from eigenvectors two to four which the metastable states are?\n",
    "\n",
    "**Exercise 4**: Estimate a Bayesian MSM at lag time $10$ ps and perform/show a CK test for four metastable states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "bayesian_msm = #FIXME\n",
    "\n",
    "nstates = 4\n",
    "pyemma.plots. #FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "bayesian_msm = pyemma.msm.bayesian_markov_model(cluster.dtrajs, lag=10)\n",
    "\n",
    "nstates = 4\n",
    "pyemma.plots.plot_cktest(bayesian_msm.cktest(nstates));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**: Coarse grain the MSM onto the four metastable states, obtain the metastable state trajectory, and visualize the metastable state memberships and the coarse-grained MSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "coarse_msm = #FIXME\n",
    "print(coarse_msm.transition_matrix)\n",
    "\n",
    "for i, s in enumerate(coarse_msm.metastable_sets):\n",
    "    print('π_{} = {:f}'.format(i, msm.pi[s].sum()))\n",
    "\n",
    "metastable_traj = #FIXME\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_state_map(*tica_out.T, metastable_traj, ax=axes[0])\n",
    "axes[0].set_xlabel('IC 1')\n",
    "axes[0].set_ylabel('IC 2')\n",
    "pyemma.plots.plot_markov_model(\n",
    "    coarse_msm,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    figpadding=0.1,\n",
    "    size=12,\n",
    "    ax=axes[1])\n",
    "axes[1].set_aspect('equal')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "coarse_msm = msm.coarse_grain(nstates)\n",
    "print(coarse_msm.transition_matrix)\n",
    "\n",
    "for i, s in enumerate(coarse_msm.metastable_sets):\n",
    "    print('π_{} = {:f}'.format(i, msm.pi[s].sum()))\n",
    "\n",
    "metastable_traj = coarse_msm.metastable_assignments[np.concatenate(cluster.dtrajs)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_state_map(*tica_out.T, metastable_traj, ax=axes[0])\n",
    "axes[0].set_xlabel('IC 1')\n",
    "axes[0].set_ylabel('IC 2')\n",
    "pyemma.plots.plot_markov_model(\n",
    "    coarse_msm,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    figpadding=0.1,\n",
    "    size=12,\n",
    "    ax=axes[1])\n",
    "axes[1].set_aspect('equal')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you guess the metastable states correctly?\n",
    "\n",
    "Note the similarities between the MSM built from the backbone torsions and the MSM built from the TICA projection of heavy atom distances. Even though we started from different features, both models found the same kinetic information in the data.\n",
    "\n",
    "**Exercise 6**: Compute the pairwise MFPTs and transition rates, and visualize the resulting kinetic network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "mfpt = np.zeros((nstates, nstates))\n",
    "for i in range(nstates):\n",
    "    for j in range(nstates):\n",
    "        mfpt[i, j] = #FIXME\n",
    "\n",
    "rate = np.zeros_like(mfpt)\n",
    "nz = mfpt.nonzero()\n",
    "rate[nz] = 1.0 / mfpt[nz]\n",
    "\n",
    "pyemma.plots.plot_network(\n",
    "    rate,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    arrow_label_format='%.1f ns',\n",
    "    arrow_labels=mfpt,\n",
    "    arrow_scale=3.0,\n",
    "    size=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mfpt = np.zeros((nstates, nstates))\n",
    "for i in range(nstates):\n",
    "    for j in range(nstates):\n",
    "        mfpt[i, j] = msm.mfpt(\n",
    "            coarse_msm.metastable_sets[i],\n",
    "            coarse_msm.metastable_sets[j])\n",
    "\n",
    "rate = np.zeros_like(mfpt)\n",
    "nz = mfpt.nonzero()\n",
    "rate[nz] = 1.0 / mfpt[nz]\n",
    "\n",
    "pyemma.plots.plot_network(\n",
    "    rate,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    arrow_label_format='%.1f ns',\n",
    "    arrow_labels=mfpt,\n",
    "    arrow_scale=3.0,\n",
    "    size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: another molecular dynamics data set (pentapeptide)\n",
    "\n",
    "**Exercise 7**: Fetch the pentapeptide data set, load the cossin transformations of the backbone and $\\chi_1$ sidechain torsions into memory, perform TICA with `lag=20` and `var_cutoff=0.9`, discretize with $250$ $k$-means centers using a stride of $10$, visualize the margial distributions, and show the ITS convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('pentapeptide-impl-solv.pdb', working_directory='data')\n",
    "files = mdshare.fetch('pentapeptide-*-500ns-impl-solv.xtc', working_directory='data')\n",
    "\n",
    "feat = #FIXME\n",
    "feat. #FIXME\n",
    "feat. #FIXME\n",
    "data = #FIXME\n",
    "\n",
    "tica = #FIXME\n",
    "tica_out = #FIXME\n",
    "cluster = #FIXME\n",
    "its = #FIXME\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_feature_histograms #FIXME\n",
    "pyemma.plots.plot_implied_timescales #FIXME\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('pentapeptide-impl-solv.pdb', working_directory='data')\n",
    "files = mdshare.fetch('pentapeptide-*-500ns-impl-solv.xtc', working_directory='data')\n",
    "\n",
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "feat.add_backbone_torsions(cossin=True)\n",
    "feat.add_sidechain_torsions(which='chi1', cossin=True)\n",
    "data = pyemma.coordinates.load(files, features=feat)\n",
    "\n",
    "tica = pyemma.coordinates.tica(data, lag=20, var_cutoff=0.9)\n",
    "tica_out = np.concatenate(tica.get_output())\n",
    "cluster = pyemma.coordinates.cluster_kmeans(tica, k=250, max_iter=50, stride=10)\n",
    "its = pyemma.msm.its(cluster.dtrajs, lags=30, nits=10, errors='bayes')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_feature_histograms(tica_out, ax=axes[0])\n",
    "pyemma.plots.plot_implied_timescales(its, ax=axes[1], dt=0.1, units='ns')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**: Estimate an MSM at lag time $12$ steps with `dt_traj='0.1 ns'` and visualize the first six right eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "msm = #FIXME\n",
    "\n",
    "print('fraction of states used = {:f}'.format(msm.active_state_fraction))\n",
    "print('fraction of counts used = {:f}'.format(msm.active_count_fraction))\n",
    "\n",
    "eigvec = msm.eigenvectors_right()\n",
    "print('first eigenvector is one: {} (min={}, max={})'.format(\n",
    "    np.allclose(eigvec[:, 0], 1, atol=1e-15), #FIXME\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pyemma.plots.plot_contour( #FIXME\n",
    "    ax.scatter(*cluster.clustercenters[:, :2].T, s=1, c='C1')\n",
    "    ax.set_xlabel('IC 1')\n",
    "    ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(\n",
    "    cluster.dtrajs, lag=12, dt_traj='0.1 ns')\n",
    "\n",
    "print('fraction of states used = {:f}'.format(msm.active_state_fraction))\n",
    "print('fraction of counts used = {:f}'.format(msm.active_count_fraction))\n",
    "\n",
    "eigvec = msm.eigenvectors_right()\n",
    "print('first eigenvector is one: {} (min={}, max={})'.format(\n",
    "    np.allclose(eigvec[:, 0], 1, atol=1e-15), eigvec[:, 0].min(), eigvec[:, 0].max()))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    pyemma.plots.plot_contour(\n",
    "        *tica_out[:, :2].T, eigvec[np.concatenate(cluster.dtrajs), i + 1], ax=ax, cmap='PiYG',\n",
    "        cbar_label='{}. right eigenvector'.format(i + 2), mask=True)\n",
    "    ax.scatter(*cluster.clustercenters[:, :2].T, s=1, c='C1')\n",
    "    ax.set_xlabel('IC 1')\n",
    "    ax.set_ylabel('IC 2')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9**: Plot the first ten timescales of the estimated MSM and look for spectral gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "timescales = #FIXME\n",
    "\n",
    "plt.plot(timescales, '-o')\n",
    "plt.xlabel('timescale index')\n",
    "plt.ylabel('timescale / ns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "timescales = msm.timescales(k=10)\n",
    "\n",
    "plt.plot(timescales, '-o')\n",
    "plt.xlabel('timescale index')\n",
    "plt.ylabel('timescale / ns');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10**: Estimate a Bayesian MSM at lag time $12$ steps and perform/show a CK test for four metastable states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "bayesian_msm = #FIXME\n",
    "\n",
    "nstates = 4\n",
    "pyemma.plots. #FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "bayesian_msm = pyemma.msm.bayesian_markov_model(cluster.dtrajs, lag=12)\n",
    "\n",
    "nstates = 4\n",
    "pyemma.plots.plot_cktest(bayesian_msm.cktest(nstates));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11**: Coarse grain the MSM onto the four metastable states, obtain the metastable state trajectory, and visualize the metastabel state memberships and the coarse-grained MSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "coarse_msm = #FIXME\n",
    "print(coarse_msm.transition_matrix)\n",
    "\n",
    "for i, s in enumerate(coarse_msm.metastable_sets):\n",
    "    print('π_{} = {:f}'.format(i, msm.pi[s].sum()))\n",
    "\n",
    "mtraj = #FIXME\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_state_map(*tica_out[:, :2].T, mtraj, ax=axes[0])\n",
    "axes[0].set_xlabel('IC 1')\n",
    "axes[0].set_ylabel('IC 2')\n",
    "pyemma.plots.plot_markov_model(\n",
    "    coarse_msm,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    figpadding=0.1,\n",
    "    size=12,\n",
    "    ax=axes[1])\n",
    "axes[1].set_aspect('equal')\n",
    "fig.tight_layout()\n",
    "\n",
    "my_samples = [pyemma.coordinates.save_traj([files], idist, outfile=None, top=pdb)\n",
    "              for idist in msm.sample_by_distributions(coarse_msm.metastable_distributions, 50)]\n",
    "\n",
    "visualize_metastable(my_samples, cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "coarse_msm = msm.coarse_grain(nstates)\n",
    "print(coarse_msm.transition_matrix)\n",
    "\n",
    "for i, s in enumerate(coarse_msm.metastable_sets):\n",
    "    print('π_{} = {:f}'.format(i, msm.pi[s].sum()))\n",
    "\n",
    "mtraj = coarse_msm.metastable_assignments[np.concatenate(cluster.dtrajs)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "pyemma.plots.plot_state_map(*tica_out[:, :2].T, mtraj, ax=axes[0])\n",
    "axes[0].set_xlabel('IC 1')\n",
    "axes[0].set_ylabel('IC 2')\n",
    "pyemma.plots.plot_markov_model(\n",
    "    coarse_msm,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    figpadding=0.1,\n",
    "    size=12,\n",
    "    ax=axes[1])\n",
    "axes[1].set_aspect('equal')\n",
    "fig.tight_layout()\n",
    "\n",
    "my_samples = [pyemma.coordinates.save_traj(files, idist, outfile=None, top=pdb)\n",
    "              for idist in msm.sample_by_distributions(coarse_msm.metastable_distributions, 50)]\n",
    "\n",
    "visualize_metastable(my_samples, cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12**: Compute the pairwise MFPTs and transition rates, and visualize the resulting kinetic network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "mfpt = np.zeros((nstates, nstates))\n",
    "for i in range(nstates):\n",
    "    for j in range(nstates):\n",
    "        mfpt[i, j] = #FIXME\n",
    "\n",
    "rate = np.zeros_like(mfpt)\n",
    "nz = mfpt.nonzero()\n",
    "rate[nz] = 1.0 / mfpt[nz]\n",
    "\n",
    "pyemma.plots.plot_network(\n",
    "    rate,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    arrow_label_format='%.1f ns',\n",
    "    arrow_labels=mfpt,\n",
    "    arrow_scale=3.0,\n",
    "    size=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mfpt = np.zeros((nstates, nstates))\n",
    "for i in range(nstates):\n",
    "    for j in range(nstates):\n",
    "        mfpt[i, j] = msm.mfpt(\n",
    "            coarse_msm.metastable_sets[i],\n",
    "            coarse_msm.metastable_sets[j])\n",
    "\n",
    "rate = np.zeros_like(mfpt)\n",
    "nz = mfpt.nonzero()\n",
    "rate[nz] = 1.0 / mfpt[nz]\n",
    "\n",
    "pyemma.plots.plot_network(\n",
    "    rate,\n",
    "    pos=np.asarray([[0, 0], [4, 0], [2, 4], [6, 4]]),\n",
    "    arrow_label_format='%.1f ns',\n",
    "    arrow_labels=mfpt,\n",
    "    arrow_scale=3.0,\n",
    "    size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "In this notebook, we have learned how to coarse grain an MSM and how to extract kinetic information from the model. In detail, we have used\n",
    "- the `active_state_fraction`, `active_count_fraction`, and `active_set` attributes of an MSM object to see how much (and which parts) of our data form the largest connected set represented by the MSM,\n",
    "- the `stationary_distribution` (or `pi`) attribute of an MSM object to access its stationary vector,\n",
    "- the `eigenvectors_right()` method of an MSM object to access its (right) eigenvectors,\n",
    "- the `coarse_grain()` method of an MSM object to coarse grain the model onto a selcted number of metastable states,\n",
    "- the `mfpt()` method of an MSM object to compute mean first passage times between metastable states which, in turn, are accessible via\n",
    "- the `metastable_sets` and `metastable_assignments` attributes of a coarse-grained MSM object.\n",
    "\n",
    "For visualizing MSMs or kinetic networks we used\n",
    "- `pyemma.plots.plot_markov_model()` and\n",
    "- `pyemma.plots.plot_network()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
