{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - common problems & bad data situations\n",
    "In this notebook, we will revise common problems that might come up when dealing with real-world data. Most problems arise from bad sampling combined with a poor discretization. For estimating a Markov model, it is required to have a connected data set, i.e. we must have observed each process we want to describe in both directions. PyEMMA checks if this requirement is fulfilled, however in certain situations this might be less obvious.\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mdshare\n",
    "import pyemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: preprocessed, two-dimensional data (toy model)\n",
    "### well-sampled double-well potential\n",
    "Let's again have a look at the double-well potential. Since we are only interested in the problematic situations here, we will simplify our data a bit and work with a 1D projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = mdshare.fetch('hmm-doublewell-2d-100k.npz', working_directory='data')\n",
    "with np.load(file) as fh:\n",
    "    data = [fh['trajectory'][:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1D_histogram_trajectories(data, cluster=None, max_traj_length=200, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    for n, _traj in enumerate(data):\n",
    "        ax.hist(_traj, bins=30, alpha=.33, density=True, color='C{}'.format(n));\n",
    "    ylims = ax.get_ylim()\n",
    "    xlims = ax.get_xlim()\n",
    "    for n, _traj in enumerate(data):\n",
    "        ax.plot(\n",
    "            _traj[:min(len(_traj), max_traj_length)], \n",
    "            np.linspace(*ylims, min(len(_traj), max_traj_length)), \n",
    "            alpha=0.6, color='C{}'.format(n), label='traj {}'.format(n))\n",
    "        if cluster is not None:\n",
    "            ax.plot(\n",
    "                cluster.clustercenters[cluster.dtrajs[n][:min(len(_traj), max_traj_length)], 0], \n",
    "                np.linspace(*ylims, min(len(_traj), max_traj_length)), \n",
    "                '.-', alpha=.6, label='dtraj {}'.format(n), linewidth=.3)\n",
    "    ax.annotate(\n",
    "        '', xy=(0.85 * xlims[1], 0.7 * ylims[1]), xytext=(0.85 * xlims[1], 0.3 * ylims[1]),\n",
    "        arrowprops=dict(fc='C0', ec='None', alpha=0.6, width=2))\n",
    "    ax.text(0.86 * xlims[1], 0.5 * ylims[1], '$x(time)$', ha='left', va='center', rotation=90)\n",
    "    ax.set_xlabel('TICA coordinate')\n",
    "    ax.set_ylabel('histogram counts & trajectory time')\n",
    "    ax.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "cluster = pyemma.coordinates.cluster_regspace(data, dmin=0.05)\n",
    "\n",
    "plot_1D_histogram_trajectories(data, cluster=cluster, ax=axes[0])\n",
    "\n",
    "lags = [i + 1 for i in range(10)]\n",
    "its = pyemma.msm.its(cluster.dtrajs, lags=lags)\n",
    "pyemma.plots.plot_implied_timescales(its, marker='o', ax=axes[1], nits=4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a nice, reversibly connected trajectory. That means we have sampled transitions between the basins in both directions and are resolved by the discretization. As we see from the almost perfect overlay of discrete and continuous trajectory, nearly no discretization error is made. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  irreversibly connected double-well trajectories\n",
    "In MD simulations, we often face the problem that a process is sampled only in one direction. For example, consider protein-protein binding. The unbinding might take on the order of seconds to minutes and is thus difficult to sample. We will have a look what happens with the MSM in this case. \n",
    "\n",
    "Our example are two trajectories sampled from a double-well potential. They will be color coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = mdshare.fetch('doublewell_oneway.npy', working_directory='data')\n",
    "data = [trj for trj in np.load(file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1D_histogram_trajectories(data, max_traj_length=data[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the orange trajectory does not leave its potential well while the blue trajectory does a transition to the other well. Thus, even though we have one transition, we do not sample the way out of one of the potential wells, thus effectively sampling a sink state. Let's have a look at the MSM. Since in higher dimensions, we often face the problem of a poor discretization, we will simulate this situation by using too few cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_fine = pyemma.coordinates.cluster_regspace(data, dmin=0.1)\n",
    "cluster_bad = pyemma.coordinates.cluster_regspace(data, dmin=0.7)\n",
    "print(cluster_fine.n_clusters, cluster_bad.n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharey='col')\n",
    "for cluster, ax in zip([cluster_bad, cluster_fine], axes):\n",
    "    plot_1D_histogram_trajectories(data, cluster=cluster, max_traj_length=data[0].shape[0], ax=ax[0])\n",
    "    its = pyemma.msm.its(cluster.dtrajs, lags=[1, 10, 100, 200, 300, 500, 800, 1000])\n",
    "    pyemma.plots.plot_implied_timescales(its, marker='o', ax=ax[1], nits=4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we see? \n",
    "\n",
    "1) We observe implied timescales that even look converged in the fine sampling case. \n",
    "\n",
    "2) With poor sampling, the process cannot be resolved any more i.e. the ITS does not convergence before the lag time exceeds the implied time scale. \n",
    "\n",
    "The obvious question is, what is the process that can be observed in the fine discretization case? PyEMMA checks for disconnectivity and thus should not find the process between the two wells. We follow this question by taking a look at the first eigenvector, which corresponds to that process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(cluster_fine.dtrajs, 200)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(\n",
    "    cluster_fine.clustercenters[msm.active_set, 0],\n",
    "    msm.eigenvectors_right()[:, 1],\n",
    "    'o:',\n",
    "    label='first eigvec')\n",
    "tx = ax.twinx()\n",
    "tx.hist(np.concatenate(data), bins=30, alpha=0.33)\n",
    "tx.set_yticklabels([])\n",
    "tx.set_yticks([])\n",
    "fig.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a process which is entirely taking place in the left potential well. How come? PyEMMA estimates Markov models only on the largest connected set, as MSMs are only defined here. In this particular example, the largest connected set is the microstates in the left potential well. That means that we find a transition between the right and the left side of this well. This is not wrong, it might just be non-informative or irrelevant. \n",
    "\n",
    "The set of microstates which is used for the MSM estimation is stored in the MSM python object and can be retrieved via `.active_set`. In this example we clearly see that some states are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msm.active_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disconnected double-well trajectories with cross-overs\n",
    "This example covers the worst-case scenario. We have two trajectories that live in two separated wells and never transition to the other one. Due to a very bad clustering, we believe that the data is connected. This can happen if we cluster a large dataset in very high dimensions where it is especially difficult to debug. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = mdshare.fetch('doublewell_disconnected.npy', working_directory='data')\n",
    "data = [trj for trj in np.load(file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1D_histogram_trajectories(data, max_traj_length=data[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_fine = pyemma.coordinates.cluster_regspace(data, dmin=0.1)\n",
    "cluster_bad = pyemma.coordinates.cluster_regspace(data, dmin=0.7)\n",
    "print(cluster_fine.n_clusters, cluster_bad.n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharey='col')\n",
    "for cluster, ax in zip([cluster_bad, cluster_fine], axes):\n",
    "    plot_1D_histogram_trajectories(data, cluster=cluster, max_traj_length=data[0].shape[0], ax=ax[0])\n",
    "    its = pyemma.msm.its(cluster.dtrajs, lags=[1, 10, 100, 200, 300, 500, 800, 1000])\n",
    "    pyemma.plots.plot_implied_timescales(its, marker='o', ax=ax[1], nits=4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we see?\n",
    "\n",
    "1) With the fine discretization, we observe some timescales that are converged. These are most probably processes within one of the wells as we saw previously.\n",
    "\n",
    "2) The poor discretization induces a large error and describes artificial short visits to the other basin.\n",
    "\n",
    "3) The timescales in the poor discretization are much higher but not converged. \n",
    "\n",
    "The reason for the high timescales in 3) are in fact the artificial cross-over events created by the poor discretization. This process was not actually sampled and is an artifact of bad clustering. Let's look at it in more detail anyway and even compute metastable states with a PCCA+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(cluster_bad.dtrajs, 200)\n",
    "\n",
    "n_states = 2\n",
    "msm.pcca(n_states)\n",
    "\n",
    "index_order = np.argsort(cluster_bad.clustercenters[:, 0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "axes[0].plot(\n",
    "    cluster_bad.clustercenters[index_order, 0],\n",
    "    msm.eigenvectors_right()[index_order, 1],\n",
    "    'o:',\n",
    "    label='1st eigvec')\n",
    "axes[0].set_title('first eigenvector')\n",
    "for n, metastable_distribution in enumerate(msm.metastable_distributions):\n",
    "    axes[1].step(\n",
    "        cluster_bad.clustercenters[index_order, 0],\n",
    "        metastable_distribution[index_order],\n",
    "        ':', \n",
    "        label='md state {}'.format(n),\n",
    "        where='mid')\n",
    "axes[1].set_title('metastable distributions (md)')\n",
    "axes[2].step(\n",
    "    cluster_bad.clustercenters[index_order, 0],\n",
    "    msm.pi[index_order],\n",
    "    'k--',\n",
    "    label='$\\pi$',\n",
    "    where='mid')\n",
    "axes[2].set_title('stationary distribution $\\pi$')\n",
    "for ax in axes:\n",
    "    tx = ax.twinx()\n",
    "    tx.hist(np.concatenate(data), bins=30, alpha=0.33)\n",
    "    tx.set_yticklabels([])\n",
    "    tx.set_yticks([])\n",
    "fig.legend(loc=7)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the first eigenvector represents a process that does not exist, i.e. is an artifact. Nevertheless, the PCCA+ algorithm can separate metastable states in a way we would expect. It finds the two disconnected states. However, the stationary distribution yields arbitrary results. \n",
    "\n",
    "#### How to detect disconnectivity?\n",
    "Generally, hidden Markov models (HMMs) are much more reliable because they come with an additional layer of hidden states. Cross-over events are thus unlikely to be counted as \"real\" transitions. Thus, it is a good idea to estimate an HMM. What happens if we take our previously estimated MSM and coarse grain it into two states with the HMM method? It is important to note that the HMM estimation is initialized from the PCCA+ metastable states that we already analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "skip": true
   },
   "outputs": [],
   "source": [
    "hmm = pyemma.msm.estimate_hidden_markov_model(cluster_bad.dtrajs, n_states, msm.lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting an error message which already explains what is going wrong, i.e. that (macro-) states are not connected and thus no unique stationary distribution can be estimated. This is equivalent to having two eigenvalues of magnitude 1 or an implied timescale of infinity which is what we observe in the implied timescales plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "its = pyemma.msm.timescales_hmsm(cluster_bad.dtrajs, n_states, lags=[1, 3, 4, 10, 100])\n",
    "pyemma.plots.plot_implied_timescales(its, marker='o', ylog=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the requested timescales above 4 steps could not be computed because the underlying HMM is disconnected, i.e. the corresponding timescales are infinity. The implied timescales that could be computed are most likely the same process that we observed from the fine clustering before, i.e. jumps within one basin.\n",
    "\n",
    "In general, is is a non-trivial problem to show that processes were not sampled reversibly. In our experience, HMMs are a good choice here, even though situations can occur where they might not detect the problem as easy as here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: low-dimensional molecular dynamics data (alanine dipeptide)\n",
    "In this example, we will show how an ill-conducted TICA analysis can yield results that look metastable in the 2D histogram, but in fact are not describing the slow dynamics. Please note that this was deliberately broken with a nonsensical TICA-lagtime of almost trajectory length, which is 250 ns.\n",
    "\n",
    "We start off with adding all atom coordinates. That's a non-optimal choice because it artificially blows up the dimensionality, but might still a reasonable choice depending on the problem. A well-conducted TICA projection can extract the slow coordinates, as we will see at the end of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('alanine-dipeptide-nowater.pdb', working_directory='data')\n",
    "files = mdshare.fetch('alanine-dipeptide-*-250ns-nowater.dcd', working_directory='data')\n",
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "\n",
    "feat.add_all()\n",
    "data = pyemma.coordinates.load(files, features=feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TICA analysis is conducted with an extremely high lag time of almost 249.9 ns. We map down to two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(data, lag=data[0].shape[0] - 100, dim=2)\n",
    "tica_output = tica.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemma.plots.plot_free_energy(*np.concatenate(tica_output).T, legacy=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the free energy plot, we recognize two defined basins that are nicely separated by the first TIC. We thus continue with a discretization of this space and estimate MSM implied timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = pyemma.coordinates.cluster_kmeans(tica_output, k=200, max_iter=30, stride=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = pyemma.msm.its(cluster.dtrajs, lags=[1, 5, 10, 20, 30, 50])\n",
    "pyemma.plots.plot_implied_timescales(its, marker='o', units='ps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we observe a converged timescale. In this example we already know that it is way lower than expected, but in the general case we are unaware of the real dynamics of the system. Thus, we estimate an MSM at lag time 20. Coarse graining and validation will be done with 2 metastable states since we found 2 basins in the free energy landscape and have one slow process in the ITS plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(cluster.dtrajs, 20)\n",
    "\n",
    "n_states = 2\n",
    "msm.pcca(n_states);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 10\n",
    "metastable_trajs_strided = [msm.metastable_assignments[dtrj[::stride]] for dtrj in cluster.dtrajs]\n",
    "tica_output_strided = [i[::stride] for i in tica_output]\n",
    "pyemma.plots.plot_state_map(*np.concatenate(tica_output_strided).T, np.concatenate(metastable_trajs_strided));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the PCCA+ algorithm is perfectly able to separate the two basins. Let's go on with a Chapman-Kolmogorow validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemma.plots.plot_cktest(msm.cktest(n_states), units='ps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, we have estimated a well-validated Markov model. The only question remaining is: What does it actually describe? For this, we usually extract representative structures as described in a previous notebook. \n",
    "\n",
    "#### What could be wrong about it?\n",
    "Let's have a look at the trajectories as assigned to PCCA coarse states. We have already computed them before but not looked at their time dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 6), sharey=True, sharex=True)\n",
    "ax_yticks_labels = []\n",
    "for n, pcca_traj in enumerate(metastable_trajs_strided):\n",
    "    ax.plot(range(len(pcca_traj)), msm.n_metastable * n + pcca_traj, color='k', linewidth=0.3)\n",
    "    ax.scatter(range(len(pcca_traj)), msm.n_metastable * n + pcca_traj, c=pcca_traj, s=0.1)\n",
    "    ax_yticks_labels.append(((msm.n_metastable * (2 * n + 1) - 1) / 2, n + 1))\n",
    "ax.set_yticks([l[0] for l in ax_yticks_labels])\n",
    "ax.set_yticklabels([str(l[1]) for l in ax_yticks_labels])\n",
    "ax.set_ylabel('Trajectory #')\n",
    "ax.set_xlabel('time / {} ps'.format(stride))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do we see?\n",
    "The above figure shows the metastable states visited by the trajectory over time. Each metastable state is color-coded, the trajectory is shown by the black line. This is clearly not a metastable trajectory as we would have expected. What did we do wrong? Let's have a look at the TICA trajectories, not only the histogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6), sharex=True, sharey='row')\n",
    "\n",
    "for n, trj in enumerate(tica_output):\n",
    "    for dim, traj1d in enumerate(trj.T):\n",
    "        axes[dim, n].plot(traj1d[::stride], linewidth=.5)\n",
    "for ax in axes[1]:\n",
    "    ax.set_xlabel('time / {} ps'.format(stride))\n",
    "for dim, ax in enumerate(axes[:, 0]):\n",
    "    ax.set_ylabel('IC {}'.format(dim + 1))\n",
    "for n, ax in enumerate(axes[0]):\n",
    "    ax.set_title('Trajectory # {}'.format(n + 1))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is essentially noise, so it is not surprising that the metastable trajectories do not show significant metastability. The MSM nevertheless found a process in the above TICs, which however does not seem to describe any of the slow dynamics. Thus, the model is not wrong, it is just uninformative. \n",
    "\n",
    "As we see in this example, it can be instructive to keep the trajectories in mind and not to rely on the histograms alone. Histograms are no proof of metastability, they can only give us a hint towards defined states in a multi-dimensional state space which can be metastable.\n",
    "\n",
    "#### How to fix it?\n",
    "In this particular example, we already know the issue: The TICA lag time was deliberately chosen way too high. That's easy to fix.\n",
    "\n",
    "Let's now have a look at how the metastable trajectories should look like for a decent model such as the one estimated in the previous notebooks. We will take the same input data, do a TICA transform with a realistic lag time of 10 ps and coarse grain into 2 metastable states in order to compare with the example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tica = pyemma.coordinates.tica(data, lag=10, dim=2)\n",
    "tica_output = tica.get_output()\n",
    "cluster = pyemma.coordinates.cluster_kmeans(tica_output, k=200, max_iter=30, stride=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemma.plots.plot_free_energy(*np.concatenate(tica_output).T, legacy=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As wee see, TICA yields a very nice state separation. We will see that these states are in fact metastable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm = pyemma.msm.estimate_markov_model(cluster.dtrajs, lag=20)\n",
    "msm.pcca(n_states);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metastable_trajs_strided = [msm.metastable_assignments[dtrj[::stride]] for dtrj in cluster.dtrajs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 10\n",
    "tica_output_strided = [i[::stride] for i in tica_output]\n",
    "pyemma.plots.plot_state_map(*np.concatenate(tica_output_strided).T, np.concatenate(metastable_trajs_strided));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that PCCA+ separates the two basins of the free energy plot. Let's have a look at the trajectories as assigned by PCCA+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6), sharey=True, sharex=True)\n",
    "ax_yticks_labels = []\n",
    "for n, pcca_traj in enumerate(metastable_trajs_strided):\n",
    "    ax.plot(range(len(pcca_traj)), msm.n_metastable * n + pcca_traj, color='k', linewidth=0.3)\n",
    "    ax.scatter(range(len(pcca_traj)), msm.n_metastable * n + pcca_traj, c=pcca_traj, s=0.1)\n",
    "    ax_yticks_labels.append(((msm.n_metastable * (2 * n + 1) - 1) / 2, n + 1))\n",
    "ax.set_yticks([l[0] for l in ax_yticks_labels])\n",
    "ax.set_yticklabels([str(l[1]) for l in ax_yticks_labels])\n",
    "ax.set_ylabel('Trajectory #')\n",
    "ax.set_xlabel('time / {} ps'.format(stride))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These trajectories show the expected behavior of a metastable trajectory, i.e. it does not quickly jump back and forth between the states.\n",
    "\n",
    "## Wrapping up\n",
    "In this notebook, we have learned about some problems that can arise when estimating MSMs with \"real world\" data at simple examples. In detail, we have seen\n",
    "\n",
    "- irreversibly connected dynamics and what it means for MSM estimation,\n",
    "- fully disconnected trajectories and how to identify them,\n",
    "- ill-conducted TICA analysis and what it yields.\n",
    "\n",
    "The most important message from this tutorial is that histograms are not a means of identifying metastability or connectedness. One should not forgot about the underlying trajectories which should play the role of the ground truth to be modeled. Histograms only help us to understand this ground truth but are not necessarily meaningful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
