{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - VAMP score based feature selection\n",
    "\n",
    "The first step to build a Markov state model is to choose a good set of collective variables to later on discretize the state space into disjoint sets. We have seen in earlier tutorial steps that this step has a huge impact on the ability to build a good model. To a certain extend Hidden Markov state models have been shown to circumvent problems arising from choosing a poor set of coordinates, but if we can make a good choice a priori this would be preferable.\n",
    "\n",
    "In this tutorial we are going to show you how to benchmark a set of coordinates at the beginning of the pipeline, instead of performing discretization and kinetic model building and validation to get the answer that we could have made a bad choice in the first place.\n",
    "\n",
    "The VAMP score helps us judging if we are using a set of coordinates, which contains more or less kinetic information. To estimate the score, PyEMMA needs to estimate three covariance matrices from your data, namely the input coordinates:\n",
    "\n",
    "$ C_{00}, C_{10}, C_{11}$\n",
    "\n",
    "where 1 denotes the correlation with a time-shifted $X$.\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mdshare\n",
    "import pyemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: preprocessed, two-dimensional data (toy model)\n",
    "We load the two-dimensional as well as the true discrete trajectory from an archive using `numpy`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = mdshare.fetch('hmm-doublewell-2d-100k.npz', working_directory='data')\n",
    "with np.load(file) as fh:\n",
    "    data = fh['trajectory']\n",
    "    good_dtraj = fh['discrete_trajectory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets select only the x coordinates to discretize state space, we intuitively know that this is a bad model choice. So this should reflect in the VAMP score computed on the input features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:, 0]\n",
    "y = data[:, 1]\n",
    "\n",
    "pyemma.plots.plot_free_energy(x, y, legacy=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vamp = pyemma.coordinates.vamp(x)\n",
    "s_x = vamp.score(x)\n",
    "print(s_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vamp = pyemma.coordinates.vamp(y)\n",
    "s_y = vamp.score(y)\n",
    "print(s_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vamp = pyemma.coordinates.vamp(data)\n",
    "s_all = vamp.score(data)\n",
    "print(s_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('contribution of x-dimension: {}'.format(s_all - s_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, that there is almost no kinetic variance along the x-axis, because the meta-stable regions are divided by a shift on the y-axis. The VAMP-2 score reflects how much kinetic variance is contained within a coordinate. The combination of x and y therefore does not increase the score much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: low-dimensional molecular dynamics data (alanine dipeptide)\n",
    "We fetch the alanine dipeptide data set, load the backbone torsions into memory, and visualize the margial and joint distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('alanine-dipeptide-nowater.pdb', working_directory='data')\n",
    "files = mdshare.fetch('alanine-dipeptide-*-250ns-nowater.dcd', working_directory='data')\n",
    "print(pdb)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reader is created with the minimum RMSD to a reference structure. This reader is passed on to the VAMP estimator to compute the covariance matrices on this feature. We specify the lag time for $C_{01}$ to 10 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_rmsd = pyemma.coordinates.source(files, top=pdb)\n",
    "reader_rmsd.featurizer.add_minrmsd_to_ref(pdb)\n",
    "\n",
    "vamp_minRMSD = pyemma.coordinates.vamp(reader_rmsd, lag=lag)\n",
    "print(vamp_minRMSD.score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us compute the score for the backbone torsion angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_bt = pyemma.coordinates.source(files, top=pdb)\n",
    "reader_bt.featurizer.add_backbone_torsions()\n",
    "\n",
    "vamp_bt = pyemma.coordinates.vamp(reader_bt, lag=lag)\n",
    "print(vamp_bt.score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check, whether the higher VAMP score of the backbone torsion angles is related to the timescales when we build a kinetic model. First of all we have a look at the feature histogram to get an idea how to discretize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pyemma.plots.plot_feature_histograms(\n",
    "    np.concatenate(reader_rmsd.get_output()))\n",
    "ax.set_title('Minimum RMSD to reference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we disretize this one dimensional space into ten states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_rmsd = pyemma.coordinates.cluster_kmeans(data, k=10, max_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and have a look at the resolved timescales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its_rmsd = pyemma.msm.its(cl_rmsd.dtrajs, lags=60)\n",
    "ax = pyemma.plots.plot_implied_timescales(its_rmsd, nits=9)\n",
    "ax.set_title('Implied timescales for minRMSD, 10 kmeans clusters.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection of the implied timescales, we see only one process, which is only closely above the actual lag time and does not seem to be converged either. Now lets compute the VAMP score for a Markov state model at a lag time of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm_rmsd = pyemma.msm.estimate_markov_model(cl_rmsd.dtrajs, lag=lag)\n",
    "print(msm_rmsd.score(cl_rmsd.dtrajs, score_k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_backbone_torsions = pyemma.coordinates.cluster_kmeans(reader_bt, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its_bt = pyemma.msm.its(cl_backbone_torsions.dtrajs, lags=60)\n",
    "pyemma.plots.plot_implied_timescales(its_bt, nits=9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implied timescales are covering three processes at lag times smaller 30 steps and two above. So the backbone torsion feature is much better suited to build a kinetic model than the minimum RMSD feature. This was already visible by inspecting the score of the VAMP estimation, whereas minRMSD yielded $\\tilde{} 1.3$, while backbone torsions got $\\tilde{} 1.4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msm_bt = pyemma.msm.estimate_markov_model(cl_backbone_torsions.dtrajs, lag=10)\n",
    "print(msm_bt.score(cl_backbone_torsions.dtrajs, score_k=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compute the VAMP score for the three slowest processes on the MSM, we see big gap between the two input features again: $\\tilde{} 1.4$ vs $\\tilde{} 2.7$. It is important to limit the number of slow processes in the scoring, because if include everything, we will add noise to the score. The noise consists out of very fast decaying processes below the actual lag time, for which we can not make any statements with the aid of the MSM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: another molecular dynamics data set (pentapeptide)\n",
    "\n",
    "**Exercise 1**: Fetch the pentapeptide data set, and compare different features in order to find an optimal input feature set. Recall the tutorial about discretization on how to select features. Compare them and discuss why the best scoring feature does describe the slow processes in the system in a physical manner. Ensure that you cap the number of processes to score to a sane number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('pentapeptide-impl-solv.pdb', working_directory='data')\n",
    "files = mdshare.fetch('pentapeptide-*-500ns-impl-solv.xtc', working_directory='data')\n",
    "\n",
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "reader = pyemma.coordinates.source(files, features=feat)\n",
    "n_processes = 10\n",
    "lag = 20\n",
    "#FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "pdb = mdshare.fetch('pentapeptide-impl-solv.pdb', working_directory='data')\n",
    "files = mdshare.fetch('pentapeptide-*-500ns-impl-solv.xtc', working_directory='data')\n",
    "\n",
    "feat = pyemma.coordinates.featurizer(pdb)\n",
    "reader = pyemma.coordinates.source(files, features=feat)\n",
    "n_processes = 10\n",
    "lag = 20\n",
    "\n",
    "\n",
    "def test_feature(feat_name, *args, **kwargs):\n",
    "    feat.active_features = []\n",
    "    getattr(feat, 'add_'+feat_name)(*args, **kwargs)\n",
    "    print('input dimension:', feat.dimension())\n",
    "    v = pyemma.coordinates.vamp(\n",
    "        reader, lag=lag, dim=min(n_processes, feat.dimension()))\n",
    "    s = v.score()\n",
    "    return s\n",
    "\n",
    "\n",
    "# define distance pairs, including every 5th neighbour\n",
    "distance_pairs = feat.pairs(np.arange(feat.topology.n_atoms), 5)\n",
    "\n",
    "features = [('backbone_torsions', (), dict(cossin=False)),\n",
    "            ('sidechain_torsions', (), {}),\n",
    "            ('distances_ca', (), {}),\n",
    "            ('distances', (distance_pairs, ), {}),\n",
    "            ('contacts', (feat.topology.select('backbone'), ), {}),\n",
    "            ]\n",
    "results = {}\n",
    "for feat_name, args, kw in features:\n",
    "    print('scoring', feat_name)\n",
    "    score = test_feature(feat_name, *args, **kw)\n",
    "    results[feat_name] = score\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (f, score) in enumerate(results.items()):\n",
    "    ax.bar(i, height=score, label=f)\n",
    "ax.legend()\n",
    "ax.set_ylabel('VAMP-2 score')\n",
    "ax.set_xticks([])\n",
    "ax.set_title(r'Input feature score with max dim={dim} and lag $\\tau={tau}$'.format(\n",
    "    dim=n_processes, tau=lag));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the most kinetic variance is included within the distance based feature. It also has the highest dimension, so it is not suprising we are able to grasp more slow processes.\n",
    "\n",
    "Now we want to use it in the next excercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Create different state space discretizations on the low-dimensional VAMP projection of the best found feature and compare them in terms of the cross-validated (scorecv) and unvalidated (score-method) VAMP-2 score of a MSM estimated at a fixed lag time. \n",
    "\n",
    "* What do you observe, when you choose too many clusters?\n",
    "* Why is it a good idea to work with a cross-validated measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "results_msm = []\n",
    "n_clusters = [10, 50, 100, 150, 200,\n",
    "              300, 500, 800, 1000][::-1]\n",
    "feat.active_features = []  # clear the active features.\n",
    "feat.add_  #FIXME\n",
    "data = pyemma.coordinates.vamp(\n",
    "    reader, dim=???, lag=???).get_output()[0]  # FIXME\n",
    "\n",
    "\n",
    "def score_discretization(k, init_centers=None):\n",
    "    \"\"\" re-estimate the kmeans object and estimate/score a MSM on the state space.\"\"\"\n",
    "    kw = {} if init_centers is None else {'clustercenters': init_centers}\n",
    "    cl.estimate(data, n_clusters=k, stride=3, **kw)\n",
    "    dtrajs = cl.assign(data)\n",
    "    msm = pyemma.msm.estimate_markov_model(dtrajs, lag=lag)\n",
    "    score_k = min(msm.nstates, n_processes)\n",
    "    # FIXME: score the msm!\n",
    "    s_cv = msm.???(score_k=score_k)\n",
    "    s=msm.???(score_k=score_k)\n",
    "    results_msm.append((k, s, s_cv))\n",
    "\n",
    "    \n",
    "# estimate the first kmeans discretization\n",
    "cl = pyemma.coordinates.cluster_kmeans(keep_data=True, max_iter=15)\n",
    "score_discretization(k=n_clusters[0])\n",
    "\n",
    "# we sub-sample the already estimated centers\n",
    "# and iterate these for a while prior estimating and scoring the MSM.\n",
    "for k in n_clusters[1:]:\n",
    "    inds=np.random.randint(0, k, size=k)\n",
    "    new_initial_centers=cl.cluster_centers_[inds]\n",
    "    score_discretization(k, init_centers=new_initial_centers)\n",
    "\n",
    "fig, ax=plt.subplots()\n",
    "for i, (x, score, scores_cv) in enumerate(results_msm):\n",
    "    y_mean=scores_cv.mean()\n",
    "    ax.errorbar(x, y=y_mean, yerr=scores_cv.std(), color='green',\n",
    "                marker='o', label='CV' if i == 0 else None)\n",
    "    ax.scatter(x, score, marker='s', color='red',\n",
    "               label='Not validated' if i == 0 else None)\n",
    "ax.set_xlabel('Number of centers')\n",
    "ax.set_ylabel('VAMP-2 score')\n",
    "ax.set_title('MSM VAMP-2 score vs. cluster centers')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "results_msm = []\n",
    "n_clusters = [10, 50, 100, 150, 200,\n",
    "              300, 500, 800, 1000][::-1]\n",
    "feat.active_features = []\n",
    "feat.add_distances(distance_pairs)\n",
    "data = pyemma.coordinates.vamp(\n",
    "    reader, dim=n_processes, lag=lag).get_output()[0]\n",
    "\n",
    "\n",
    "def score_discretization(k, init_centers=None):\n",
    "    \"\"\" re-estimate the kmeans object and estimate/score a MSM on the state space.\"\"\"\n",
    "    kw = {} if init_centers is None else {'clustercenters':init_centers}\n",
    "    cl.estimate(data, n_clusters=k, stride=3, **kw)\n",
    "    dtrajs = cl.assign(data)\n",
    "    msm = pyemma.msm.estimate_markov_model(dtrajs, lag=lag)\n",
    "    score_k = min(msm.nstates, n_processes)\n",
    "    s_cv = msm.score_cv(dtrajs, score_k=score_k)\n",
    "    s = msm.score(dtrajs, score_k=score_k)\n",
    "    results_msm.append((k, s, s_cv))\n",
    "\n",
    "\n",
    "# estimate the first kmeans discretization\n",
    "cl = pyemma.coordinates.cluster_kmeans(keep_data=True, max_iter=15)\n",
    "score_discretization(k=n_clusters[0])\n",
    "\n",
    "# we sub-sample the already estimated centers\n",
    "# and iterate these for a while prior estimating and scoring the MSM.\n",
    "for k in n_clusters[1:]:\n",
    "    inds = np.random.randint(0, k, size=k)\n",
    "    new_initial_centers = cl.cluster_centers_[inds]\n",
    "    score_discretization(k, init_centers=new_initial_centers)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, (x, score, scores_cv) in enumerate(results_msm):\n",
    "    y_mean = scores_cv.mean()\n",
    "    ax.errorbar(x, y=y_mean, yerr=scores_cv.std(), color='green',\n",
    "                marker='o', label='CV' if i == 0 else None)\n",
    "    ax.scatter(x, score, marker='s', color='red',\n",
    "               label='Not validated' if i == 0 else None)\n",
    "ax.set_xlabel('Number of centers')\n",
    "ax.set_ylabel('VAMP-2 score')\n",
    "ax.set_title('MSM VAMP-2 score vs. cluster centers')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "In this notebook, we have learned how to evaluate the quality of input features in terms of maximizing the amount kinetic information with `pyemma`. In detail, we have used\n",
    "- `v = pyemma.coordinates.vamp()` to estimate covariances of the input features\n",
    "- `v.score(data)` to compute the VAMP score on the covariances.\n",
    "- `pyemma.msm.MSM.score()` to judge the final quality of the estimated Markov state model.\n",
    "- `pyemma.msm.MSM.score_cv()` to have a cross-validated measure of the quality of the MSM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
